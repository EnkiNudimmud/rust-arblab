{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3a98f4",
   "metadata": {},
   "source": [
    "# Anomaly Detection on Superspace of Time Series Data\n",
    "## Advanced Statistical Arbitrage using Supersymmetry and Ghost Fields\n",
    "\n",
    "**Author**: HFT Arbitrage Lab  \n",
    "**Date**: December 6, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook implements cutting-edge mathematical physics concepts‚Äî**supermanifolds**, **ghost fields**, and **Chern-Simons theory**‚Äîto detect anomalies in financial time series for statistical arbitrage.\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Superspace**: Extension of classical phase space with fermionic (Grassmann) coordinates\n",
    "2. **Ghost Fields**: Auxiliary variables encoding hidden correlations and market regimes\n",
    "3. **Chern-Simons Theory**: Topological field theory capturing non-local market dynamics\n",
    "4. **14-Dimensional Modeling**: 7 bosonic + 7 fermionic dimensions for complete market representation\n",
    "\n",
    "### Applications:\n",
    "- Enhanced cointegration detection\n",
    "- Anomaly-based entry signals for pairs trading\n",
    "- Regime change identification\n",
    "- Non-linear correlation discovery\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Mathematical Foundations](#foundations)\n",
    "2. [Ghost Fields Theory](#ghost-fields)\n",
    "3. [Superspace Construction](#superspace)\n",
    "4. [Chern-Simons Invariants](#chern-simons)\n",
    "5. [14D Market Modeling](#14d-model)\n",
    "6. [Anomaly Detection Pipeline](#anomaly-detection)\n",
    "7. [Statistical Arbitrage Strategy](#strategy)\n",
    "8. [Backtesting & Results](#results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab58eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympy\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [sympy]‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/2\u001b[0m [sympy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mpmath-1.3.0 sympy-1.14.0\n",
      "‚úì All imports successful!\n",
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.3.3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.stats' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumPy version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPandas version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpd.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSciPy version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstats\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__version__\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSymPy version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msp.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'scipy.stats' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# Core numerical and scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "\n",
    "# Machine learning and data preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Symbolic mathematics (install if needed)\n",
    "try:\n",
    "    import sympy as sp\n",
    "except ImportError:\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sympy'])\n",
    "    import sympy as sp\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotly for interactive plots\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "except ImportError:\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'plotly'])\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì All imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"SciPy version: {scipy.__version__}\")\n",
    "print(f\"SymPy version: {sp.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aacd98",
   "metadata": {},
   "source": [
    "<a id='foundations'></a>\n",
    "## 1. Mathematical Foundations: Supermanifolds and Grassmann Algebra\n",
    "\n",
    "### 1.1 Introduction to Supermanifolds\n",
    "\n",
    "A **supermanifold** $\\mathcal{M}$ is a mathematical space that extends classical manifolds by including both:\n",
    "- **Bosonic coordinates** $x^\\mu$ (commuting, $x^\\mu x^\\nu = x^\\nu x^\\mu$)\n",
    "- **Fermionic coordinates** $\\theta^\\alpha$ (anti-commuting, $\\theta^\\alpha \\theta^\\beta = -\\theta^\\beta \\theta^\\alpha$)\n",
    "\n",
    "Mathematically, a point on the supermanifold is represented as:\n",
    "\n",
    "$$\n",
    "\\mathcal{P} = (x^0, x^1, \\ldots, x^{d_b-1}, \\theta^1, \\theta^2, \\ldots, \\theta^{d_f})\n",
    "$$\n",
    "\n",
    "where $d_b$ = bosonic dimensions, $d_f$ = fermionic dimensions.\n",
    "\n",
    "### 1.2 Grassmann Numbers\n",
    "\n",
    "Fermionic coordinates $\\theta^\\alpha$ are **Grassmann numbers** satisfying:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta^\\alpha \\theta^\\beta &= -\\theta^\\beta \\theta^\\alpha \\quad \\text{(anti-commutation)} \\\\\n",
    "(\\theta^\\alpha)^2 &= 0 \\quad \\text{(nilpotency)} \\\\\n",
    "\\{\\theta^\\alpha, \\theta^\\beta\\} &= \\theta^\\alpha \\theta^\\beta + \\theta^\\beta \\theta^\\alpha = 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Key Properties:**\n",
    "1. Any function of Grassmann variables terminates at finite order (Taylor series truncates)\n",
    "2. Integration and differentiation coincide: $\\int d\\theta^\\alpha \\, \\theta^\\alpha = 1$\n",
    "3. Grassmann variables encode fermionic degrees of freedom (like spin)\n",
    "\n",
    "### 1.3 Superfields\n",
    "\n",
    "A **superfield** $\\Phi(x,\\theta)$ is a function on the supermanifold:\n",
    "\n",
    "$$\n",
    "\\Phi(x,\\theta) = \\phi(x) + \\theta \\psi(x) + \\frac{1}{2}\\theta^2 F(x)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\phi(x)$: scalar field (price/observable)\n",
    "- $\\psi(x)$: spinor field (momentum/derivative info)\n",
    "- $F(x)$: auxiliary field (higher-order corrections)\n",
    "\n",
    "**Financial Interpretation:**\n",
    "- $\\phi(t)$ = asset price at time $t$\n",
    "- $\\psi(t)$ = encoded momentum/volatility information  \n",
    "- $F(t)$ = market stress/regime indicator\n",
    "\n",
    "### 1.4 Why Supermanifolds for Finance?\n",
    "\n",
    "**Traditional Approach:** Time series $\\{p_t\\}$ lives in $\\mathbb{R}^n$\n",
    "\n",
    "**Superspace Approach:** Time series $(p_t, \\theta_t)$ lives in $\\mathbb{R}^{d_b} \\times \\mathbb{G}^{d_f}$\n",
    "\n",
    "**Advantages:**\n",
    "1. **Captures hidden correlations** through fermionic sector\n",
    "2. **Natural regime encoding** in ghost field dynamics\n",
    "3. **Topological invariants** detect structural changes\n",
    "4. **Supersymmetry** relates different market observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc93149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Grassmann Algebra\n",
    "\n",
    "class GrassmannNumber:\n",
    "    \"\"\"\n",
    "    Implements Grassmann numbers with anti-commutation relations.\n",
    "    Truncates at degree 2 due to nilpotency (Œ∏¬≤ = 0).\n",
    "    \"\"\"\n",
    "    def __init__(self, scalar=0.0, grassmann=0.0):\n",
    "        \"\"\"\n",
    "        Initialize a Grassmann number: a + bŒ∏\n",
    "        \n",
    "        Args:\n",
    "            scalar: Bosonic (commuting) part\n",
    "            grassmann: Fermionic (anti-commuting) part\n",
    "        \"\"\"\n",
    "        self.scalar = float(scalar)\n",
    "        self.grassmann = float(grassmann)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        \"\"\"Addition: (a + bŒ∏) + (c + dŒ∏) = (a+c) + (b+d)Œ∏\"\"\"\n",
    "        if isinstance(other, (int, float)):\n",
    "            return GrassmannNumber(self.scalar + other, self.grassmann)\n",
    "        return GrassmannNumber(\n",
    "            self.scalar + other.scalar,\n",
    "            self.grassmann + other.grassmann\n",
    "        )\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"\n",
    "        Multiplication with anti-commutation:\n",
    "        (a + bŒ∏)(c + dŒ∏) = ac + (ad + bc)Œ∏ + bd¬∑Œ∏¬≤ = ac + (ad + bc)Œ∏\n",
    "        Note: Œ∏¬≤ = 0 (nilpotency)\n",
    "        \"\"\"\n",
    "        if isinstance(other, (int, float)):\n",
    "            return GrassmannNumber(\n",
    "                self.scalar * other,\n",
    "                self.grassmann * other\n",
    "            )\n",
    "        return GrassmannNumber(\n",
    "            self.scalar * other.scalar,\n",
    "            self.scalar * other.grassmann + self.grassmann * other.scalar\n",
    "        )\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + (other * -1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.scalar:.4f} + {self.grassmann:.4f}Œ∏\"\n",
    "    \n",
    "    def conjugate(self):\n",
    "        \"\"\"Complex conjugation (for anti-ghost fields): Œ∏ÃÑ\"\"\"\n",
    "        return GrassmannNumber(self.scalar, -self.grassmann)\n",
    "\n",
    "# Demonstrate Grassmann algebra\n",
    "print(\"=\" * 60)\n",
    "print(\"GRASSMANN NUMBER EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "Œ∏1 = GrassmannNumber(1.0, 0.5)\n",
    "Œ∏2 = GrassmannNumber(2.0, 0.3)\n",
    "\n",
    "print(f\"Œ∏‚ÇÅ = {Œ∏1}\")\n",
    "print(f\"Œ∏‚ÇÇ = {Œ∏2}\")\n",
    "print(f\"Œ∏‚ÇÅ + Œ∏‚ÇÇ = {Œ∏1 + Œ∏2}\")\n",
    "print(f\"Œ∏‚ÇÅ √ó Œ∏‚ÇÇ = {Œ∏1 * Œ∏2}\")\n",
    "print(f\"Œ∏‚ÇÅ √ó Œ∏‚ÇÅ (should have zero Œ∏¬≤ term) = {Œ∏1 * Œ∏1}\")\n",
    "print(f\"Conjugate Œ∏ÃÑ‚ÇÅ = {Œ∏1.conjugate()}\")\n",
    "\n",
    "# Verify anti-commutation: {Œ∏‚ÇÅ, Œ∏‚ÇÇ} = 0\n",
    "anticomm = (Œ∏1 * Œ∏2).grassmann + (Œ∏2 * Œ∏1).grassmann\n",
    "print(f\"\\nAnti-commutator {{Œ∏‚ÇÅ,Œ∏‚ÇÇ}} grassmann part = {anticomm:.6f} (should be ~0)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b81c3",
   "metadata": {},
   "source": [
    "<a id='ghost-fields'></a>\n",
    "## 2. Ghost Fields and Anti-Ghost Fields in Time Series\n",
    "\n",
    "### 2.1 Physical Motivation\n",
    "\n",
    "In gauge theories (like QCD, electromagnetism), **ghost fields** arise from:\n",
    "1. **Gauge redundancy**: Multiple field configurations describe same physics\n",
    "2. **Path integral quantization**: Need to factor out gauge orbit volume\n",
    "3. **Faddeev-Popov determinant**: Introduces fermionic ghost fields $c(x)$\n",
    "\n",
    "### 2.2 Ghost Field Properties\n",
    "\n",
    "**Defining Relations:**\n",
    "$$\n",
    "\\begin{align}\n",
    "\\{c^a(x), c^b(y)\\} &= 0 \\quad \\text{(anti-commutation)} \\\\\n",
    "\\{c^a(x), \\bar{c}^b(y)\\} &= 0 \\\\\n",
    "\\{\\bar{c}^a(x), \\bar{c}^b(y)\\} &= 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**BRST Transformation:**\n",
    "$$\n",
    "\\begin{align}\n",
    "\\delta_{\\text{BRST}} c^a &= \\frac{1}{2}f^{abc}c^b c^c \\\\\n",
    "\\delta_{\\text{BRST}} \\bar{c}^a &= B^a \\quad \\text{(auxiliary field)} \\\\\n",
    "\\delta_{\\text{BRST}} A_\\mu^a &= D_\\mu^{ab} c^b\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Nilpotency:**\n",
    "$$\\delta_{\\text{BRST}}^2 = 0$$\n",
    "\n",
    "This is the **key property** that ensures physical state consistency!\n",
    "\n",
    "### 2.3 Financial Interpretation\n",
    "\n",
    "**Ghost Field** $c(t)$:\n",
    "- Represents \"hidden market momentum\" \n",
    "- Encodes correlations not visible in price alone\n",
    "- Coupling to price: $\\mathcal{L}_{\\text{int}} = g \\, p(t) c(t) \\bar{c}(t)$\n",
    "\n",
    "**Anti-Ghost Field** $\\bar{c}(t)$:\n",
    "- Conjugate to ghost field\n",
    "- Related to market entropy production\n",
    "\n",
    "**Divergence Metric:**\n",
    "$$D(t) = ||\\nabla \\cdot c(t)|| = \\sqrt{\\sum_i \\left(\\frac{\\partial c^i}{\\partial x^i}\\right)^2}$$\n",
    "\n",
    "**Interpretation:**\n",
    "- $D(t) \\to \\infty$: Ghost field \"diverges\" ‚Üí **Market anomaly!**\n",
    "- Normal regime: $D(t)$ small and stable\n",
    "- Crisis: $D(t)$ explodes\n",
    "\n",
    "### 2.4 Evolution Equations\n",
    "\n",
    "Ghost fields evolve according to:\n",
    "$$\n",
    "\\frac{\\partial c^a}{\\partial t} = -\\{H_{\\text{market}}, c^a\\} + \\eta^a(t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $H_{\\text{market}}$: Market Hamiltonian (total \"energy\")\n",
    "- $\\eta^a(t)$: Stochastic noise (market randomness)\n",
    "- $\\{\\cdot, \\cdot\\}$: Poisson bracket\n",
    "\n",
    "**Hamiltonian:**\n",
    "$$H_{\\text{market}} = \\frac{1}{2}\\sum_i p_i^2 + V(q_1, \\ldots, q_n)$$\n",
    "\n",
    "where $p_i$ = price momentum, $q_i$ = positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d18bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Ghost Field Evolution\n",
    "\n",
    "class GhostFieldSystem:\n",
    "    \"\"\"\n",
    "    Simulates ghost field dynamics for financial time series.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_dims=7, dt=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_dims: Number of ghost field components\n",
    "            dt: Time step\n",
    "        \"\"\"\n",
    "        self.n_dims = n_dims\n",
    "        self.dt = dt\n",
    "        \n",
    "    def compute_hamiltonian(self, prices, volumes):\n",
    "        \"\"\"\n",
    "        Market Hamiltonian: H = ¬ΩŒ£p¬≤ + V(q)\n",
    "        \n",
    "        Args:\n",
    "            prices: Asset prices (n_assets, n_time)\n",
    "            volumes: Trading volumes\n",
    "        \n",
    "        Returns:\n",
    "            H: Hamiltonian time series\n",
    "        \"\"\"\n",
    "        # Momentum term (kinetic energy)\n",
    "        momentum = np.diff(prices, axis=1, prepend=prices[:, [0]])\n",
    "        kinetic = 0.5 * np.sum(momentum**2, axis=0)\n",
    "        \n",
    "        # Potential term (interaction energy)\n",
    "        # Use negative log-likelihood as potential\n",
    "        potential = -np.log(volumes + 1e-10)\n",
    "        \n",
    "        return kinetic + potential\n",
    "    \n",
    "    def evolve_ghost_field(self, c_init, hamiltonian, noise_std=0.1, n_steps=100):\n",
    "        \"\"\"\n",
    "        Evolve ghost field: ‚àÇc/‚àÇt = -{H, c} + Œ∑(t)\n",
    "        \n",
    "        Args:\n",
    "            c_init: Initial ghost field state (n_dims,)\n",
    "            hamiltonian: Hamiltonian time series\n",
    "            noise_std: Noise strength\n",
    "            n_steps: Number of time steps\n",
    "        \n",
    "        Returns:\n",
    "            c_trajectory: (n_steps, n_dims) ghost field evolution\n",
    "        \"\"\"\n",
    "        c = c_init.copy()\n",
    "        trajectory = np.zeros((n_steps, self.n_dims))\n",
    "        trajectory[0] = c\n",
    "        \n",
    "        for t in range(1, n_steps):\n",
    "            # Poisson bracket term (approximation)\n",
    "            poisson = -np.gradient(hamiltonian)[t] * c\n",
    "            \n",
    "            # Stochastic noise\n",
    "            noise = np.random.normal(0, noise_std, self.n_dims)\n",
    "            \n",
    "            # Update\n",
    "            c = c + self.dt * (poisson + noise)\n",
    "            trajectory[t] = c\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def compute_divergence(self, ghost_field_trajectory):\n",
    "        \"\"\"\n",
    "        Compute ‚àá¬∑c = Œ£·µ¢ ‚àÇc‚Å±/‚àÇx‚Å±\n",
    "        \n",
    "        Args:\n",
    "            ghost_field_trajectory: (T, n_dims) ghost fields\n",
    "        \n",
    "        Returns:\n",
    "            divergence: (T,) divergence time series\n",
    "        \"\"\"\n",
    "        T, n = ghost_field_trajectory.shape\n",
    "        divergence = np.zeros(T)\n",
    "        \n",
    "        for i in range(n):\n",
    "            grad_i = np.gradient(ghost_field_trajectory[:, i], self.dt)\n",
    "            divergence += grad_i\n",
    "        \n",
    "        return np.abs(divergence)\n",
    "\n",
    "# Demo: Create synthetic price data and evolve ghost fields\n",
    "np.random.seed(42)\n",
    "T = 500\n",
    "n_assets = 3\n",
    "\n",
    "# Generate correlated price movements\n",
    "prices = 100 * np.exp(np.cumsum(np.random.randn(n_assets, T) * 0.02, axis=1))\n",
    "volumes = 1000 + 500 * np.random.rand(n_assets, T)\n",
    "\n",
    "# Initialize ghost field system\n",
    "gfs = GhostFieldSystem(n_dims=7, dt=1.0)\n",
    "\n",
    "# Compute Hamiltonian\n",
    "H = gfs.compute_hamiltonian(prices, volumes)\n",
    "\n",
    "# Evolve ghost fields\n",
    "c_init = np.random.randn(7) * 0.1\n",
    "ghost_trajectory = gfs.evolve_ghost_field(c_init, H, noise_std=0.05, n_steps=T)\n",
    "\n",
    "# Compute divergence\n",
    "divergence = gfs.compute_divergence(ghost_trajectory)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "axes[0].plot(prices.T, alpha=0.7)\n",
    "axes[0].set_title('Synthetic Asset Prices')\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].legend([f'Asset {i+1}' for i in range(n_assets)])\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(H)\n",
    "axes[1].set_title('Market Hamiltonian H(t)')\n",
    "axes[1].set_ylabel('Energy')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(ghost_trajectory[:, :3], alpha=0.7)\n",
    "axes[2].set_title('Ghost Field Components c¬π, c¬≤, c¬≥')\n",
    "axes[2].set_ylabel('Ghost Field')\n",
    "axes[2].legend([f'c{i+1}' for i in range(3)])\n",
    "axes[2].grid(True)\n",
    "\n",
    "axes[3].plot(divergence, label='‚àá¬∑c(t)', color='red')\n",
    "axes[3].axhline(np.mean(divergence) + 3*np.std(divergence), \n",
    "                ls='--', c='black', label='3œÉ threshold')\n",
    "axes[3].set_title('Ghost Field Divergence (Anomaly Indicator)')\n",
    "axes[3].set_ylabel('|‚àá¬∑c|')\n",
    "axes[3].set_xlabel('Time')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True)\n",
    "\n",
    "# Mark anomalies\n",
    "threshold = np.mean(divergence) + 3*np.std(divergence)\n",
    "anomalies = divergence > threshold\n",
    "axes[3].scatter(np.where(anomalies)[0], divergence[anomalies], \n",
    "                c='red', marker='x', s=100, zorder=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nDetected {np.sum(anomalies)} anomalies out of {T} periods ({100*np.sum(anomalies)/T:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e170b4",
   "metadata": {},
   "source": [
    "## 3. Chern-Simons Invariants in (2+1) Dimensions\n",
    "\n",
    "<a id='chern-simons'></a>\n",
    "\n",
    "### Physical Origin\n",
    "\n",
    "The **Chern-Simons theory** is a topological quantum field theory in (2+1) dimensions. Unlike ordinary field theories that depend on local metric structure, CS theory captures *global* topological properties.\n",
    "\n",
    "**Action:**\n",
    "$$\n",
    "S_{CS}[A] = \\frac{k}{4\\pi} \\int_{\\mathcal{M}} \\text{Tr}\\left(A \\wedge dA + \\frac{2}{3}A \\wedge A \\wedge A\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $A$ is a gauge connection (1-form)\n",
    "- $\\mathcal{M}$ is a 3-dimensional spacetime manifold\n",
    "- $k$ is the level (integer quantization)\n",
    "- The trace is over gauge group indices\n",
    "\n",
    "**Key Property:** The action is invariant under smooth deformations of the metric‚Äîit only depends on the *topology* of $\\mathcal{M}$.\n",
    "\n",
    "### Financial Interpretation\n",
    "\n",
    "In finance, we interpret:\n",
    "- **Space dimensions (x, y):** Price coordinates for two assets in a pair\n",
    "- **Time dimension (t):** Chronological time\n",
    "- **Gauge field $A$:** Encodes price-volume flow: $A_\\mu = (p_1, p_2, V)$\n",
    "\n",
    "The CS invariant captures **topological invariance of price-volume trajectories** under smooth market fluctuations. It detects:\n",
    "1. **Regime changes**: When topology of price trajectory changes\n",
    "2. **Structural breaks**: Abrupt changes in CS value signal fundamental shifts\n",
    "3. **Hidden correlations**: Non-local relationships between assets\n",
    "\n",
    "### Discrete Implementation\n",
    "\n",
    "For discrete time series, we approximate:\n",
    "\n",
    "$$\n",
    "\\text{CS}(t) = \\sum_{i=1}^{N-1} \\left[ \\Delta p_i \\cdot \\left(\\frac{\\Delta V_i}{\\Delta t}\\right) - \\frac{1}{3}(\\Delta p_i)^3 \\right]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\Delta p_i = p_{i+1} - p_i$ (price increment)\n",
    "- $\\Delta V_i = V_{i+1} - V_i$ (volume increment)\n",
    "- Window size $N$ (typically 20-50 periods)\n",
    "\n",
    "**Anomaly Detection:** Large changes in $|\\text{CS}(t) - \\text{CS}(t-1)|$ indicate topological transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chern_simons_invariant(prices, volumes, window=20):\n",
    "    \"\"\"\n",
    "    Compute discrete Chern-Simons invariant for price-volume trajectory.\n",
    "    \n",
    "    CS(t) = Œ£·µ¢ [Œîp·µ¢ ¬∑ (ŒîV·µ¢/Œît) - ‚Öì(Œîp·µ¢)¬≥]\n",
    "    \n",
    "    Args:\n",
    "        prices: (T,) array of prices\n",
    "        volumes: (T,) array of volumes\n",
    "        window: Rolling window size\n",
    "    \n",
    "    Returns:\n",
    "        cs_values: (T-window,) Chern-Simons time series\n",
    "        cs_changes: (T-window-1,) changes in CS (anomaly signal)\n",
    "    \"\"\"\n",
    "    T = len(prices)\n",
    "    cs_values = np.zeros(T - window + 1)\n",
    "    \n",
    "    for t in range(window, T + 1):\n",
    "        # Extract window\n",
    "        p_window = prices[t-window:t]\n",
    "        v_window = volumes[t-window:t]\n",
    "        \n",
    "        # Compute increments\n",
    "        dp = np.diff(p_window)\n",
    "        dv = np.diff(v_window)\n",
    "        \n",
    "        # CS formula (discrete approximation)\n",
    "        term1 = dp * dv  # Price-volume coupling\n",
    "        term2 = (1/3) * dp**3  # Cubic self-interaction\n",
    "        \n",
    "        cs_values[t - window] = np.sum(term1 - term2)\n",
    "    \n",
    "    # Compute changes (anomaly indicator)\n",
    "    cs_changes = np.abs(np.diff(cs_values))\n",
    "    \n",
    "    return cs_values, cs_changes\n",
    "\n",
    "\n",
    "# Apply to our synthetic data\n",
    "cs_asset1, cs_changes1 = chern_simons_invariant(prices[0], volumes[0], window=30)\n",
    "cs_asset2, cs_changes2 = chern_simons_invariant(prices[1], volumes[1], window=30)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Original prices\n",
    "axes[0].plot(prices[0], label='Asset 1 Price', alpha=0.7)\n",
    "axes[0].plot(prices[1], label='Asset 2 Price', alpha=0.7)\n",
    "axes[0].set_title('Asset Prices')\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# CS invariants\n",
    "time_cs = np.arange(30, len(prices[0]) + 1)\n",
    "axes[1].plot(time_cs, cs_asset1, label='CS(Asset 1)', alpha=0.7)\n",
    "axes[1].plot(time_cs, cs_asset2, label='CS(Asset 2)', alpha=0.7)\n",
    "axes[1].set_title('Chern-Simons Invariants')\n",
    "axes[1].set_ylabel('CS Value')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# CS changes (anomaly signal)\n",
    "time_changes = np.arange(31, len(prices[0]) + 1)\n",
    "axes[2].plot(time_changes, cs_changes1, label='|ŒîCS| Asset 1', alpha=0.7)\n",
    "axes[2].plot(time_changes, cs_changes2, label='|ŒîCS| Asset 2', alpha=0.7)\n",
    "\n",
    "# Detect topological transitions\n",
    "threshold_cs = np.percentile(cs_changes1, 95)\n",
    "axes[2].axhline(threshold_cs, ls='--', c='red', label='95th percentile')\n",
    "axes[2].set_title('Chern-Simons Changes (Topological Transitions)')\n",
    "axes[2].set_ylabel('|ŒîCS|')\n",
    "axes[2].set_xlabel('Time')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# Mark transitions\n",
    "transitions1 = cs_changes1 > threshold_cs\n",
    "axes[2].scatter(time_changes[transitions1], cs_changes1[transitions1], \n",
    "                c='red', marker='D', s=100, zorder=5, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detected {np.sum(transitions1)} topological transitions in Asset 1\")\n",
    "print(f\"Mean CS change: {np.mean(cs_changes1):.4f}\")\n",
    "print(f\"Std CS change: {np.std(cs_changes1):.4f}\")\n",
    "print(f\"95th percentile threshold: {threshold_cs:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b7ba8",
   "metadata": {},
   "source": [
    "## 4. The 14-Dimensional Financial Superspace\n",
    "\n",
    "<a id='14d-superspace'></a>\n",
    "\n",
    "### Construction\n",
    "\n",
    "We construct the superspace $\\mathcal{S}_{14}$ with coordinates $(x^0, x^1, \\ldots, x^6; \\theta^1, \\ldots, \\theta^7)$:\n",
    "\n",
    "#### Bosonic Coordinates (7 dimensions)\n",
    "1. **$x^0$ - Log Price:** $x^0(t) = \\log(P(t))$\n",
    "2. **$x^1$ - Log Volume:** $x^1(t) = \\log(V(t))$\n",
    "3. **$x^2$ - Volatility:** $\\sigma(t) = \\text{std}(r_{t-n:t})$ where $r = \\log(P_t/P_{t-1})$\n",
    "4. **$x^3$ - Trend:** Moving average slope: $\\beta = \\frac{\\text{cov}(t, P)}{\\text{var}(t)}$\n",
    "5. **$x^4$ - Momentum:** Rate of change: $\\text{ROC}(t) = \\frac{P(t) - P(t-k)}{P(t-k)}$\n",
    "6. **$x^5$ - Liquidity:** Bid-ask spread or Amihud illiquidity\n",
    "7. **$x^6$ - Sentiment:** Technical indicator (RSI, MACD, etc.)\n",
    "\n",
    "#### Fermionic Coordinates (7 dimensions)\n",
    "Each $\\theta^i$ is a **ghost field** corresponding to $x^i$:\n",
    "\n",
    "$$\n",
    "\\theta^i(t) = f_i\\left(\\frac{\\partial H}{\\partial x^i}\\right) + \\epsilon^i(t)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $H$ is the market Hamiltonian\n",
    "- $f_i$ is a response function (e.g., $\\tanh$ or linear)\n",
    "- $\\epsilon^i(t)$ is stochastic noise\n",
    "\n",
    "The ghost fields encode:\n",
    "- **Hidden correlations** between observables\n",
    "- **Entropy flows** not visible in bosonic coordinates\n",
    "- **Early warning signals** for regime changes\n",
    "\n",
    "### Superfield Expansion\n",
    "\n",
    "A superfield on $\\mathcal{S}_{14}$ expands as:\n",
    "\n",
    "$$\n",
    "\\Phi(x, \\theta) = \\phi(x) + \\sum_{i=1}^7 \\theta^i \\psi_i(x) + \\sum_{i<j} \\theta^i \\theta^j F_{ij}(x) + \\ldots\n",
    "$$\n",
    "\n",
    "Truncating at quadratic order (since $\\theta^i \\theta^i = 0$):\n",
    "- $\\phi(x)$: Ordinary bosonic field (e.g., log price)\n",
    "- $\\psi_i(x)$: Fermionic partners (ghost fields)\n",
    "- $F_{ij}(x)$: Auxiliary fields (higher-order correlations)\n",
    "\n",
    "### Why 14 Dimensions?\n",
    "\n",
    "**Mathematical:** Supersymmetry requires equal numbers of bosonic and fermionic degrees of freedom.\n",
    "\n",
    "**Financial:** The 7 bosonic variables capture standard market observables. The 7 fermionic ghosts capture:\n",
    "1. Non-equilibrium dynamics\n",
    "2. Information flow not in prices\n",
    "3. Entropy production\n",
    "4. Leading indicators of instability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Superspace14D:\n",
    "    \"\"\"\n",
    "    14-dimensional superspace for financial time series.\n",
    "    7 bosonic + 7 fermionic dimensions.\n",
    "    \"\"\"\n",
    "    def __init__(self, window=20):\n",
    "        self.window = window\n",
    "        \n",
    "    def compute_bosonic_coords(self, prices, volumes):\n",
    "        \"\"\"\n",
    "        Compute 7 bosonic coordinates from price/volume data.\n",
    "        \n",
    "        Returns:\n",
    "            X: (T, 7) array of bosonic coordinates\n",
    "        \"\"\"\n",
    "        T = len(prices)\n",
    "        X = np.zeros((T, 7))\n",
    "        \n",
    "        # x^0: Log price\n",
    "        X[:, 0] = np.log(prices + 1e-10)\n",
    "        \n",
    "        # x^1: Log volume\n",
    "        X[:, 1] = np.log(volumes + 1e-10)\n",
    "        \n",
    "        # x^2: Volatility (rolling std of returns)\n",
    "        returns = np.diff(np.log(prices + 1e-10), prepend=np.log(prices[0]))\n",
    "        X[:, 2] = pd.Series(returns).rolling(self.window, min_periods=1).std().values\n",
    "        \n",
    "        # x^3: Trend (rolling regression slope)\n",
    "        for t in range(T):\n",
    "            start = max(0, t - self.window + 1)\n",
    "            y = prices[start:t+1]\n",
    "            x = np.arange(len(y))\n",
    "            if len(y) > 1:\n",
    "                X[t, 3] = np.polyfit(x, y, 1)[0]\n",
    "        \n",
    "        # x^4: Momentum (rate of change)\n",
    "        k = min(10, self.window // 2)\n",
    "        X[:, 4] = (prices - np.roll(prices, k)) / (np.roll(prices, k) + 1e-10)\n",
    "        X[:k, 4] = 0  # Handle initial periods\n",
    "        \n",
    "        # x^5: Liquidity proxy (inverse of volume)\n",
    "        X[:, 5] = 1.0 / (volumes + 1e-10)\n",
    "        \n",
    "        # x^6: Sentiment (RSI-like indicator)\n",
    "        gains = np.maximum(np.diff(prices, prepend=prices[0]), 0)\n",
    "        losses = -np.minimum(np.diff(prices, prepend=prices[0]), 0)\n",
    "        avg_gain = pd.Series(gains).rolling(14, min_periods=1).mean().values\n",
    "        avg_loss = pd.Series(losses).rolling(14, min_periods=1).mean().values\n",
    "        rs = avg_gain / (avg_loss + 1e-10)\n",
    "        X[:, 6] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def compute_fermionic_coords(self, X, noise_level=0.1):\n",
    "        \"\"\"\n",
    "        Compute 7 fermionic ghost field coordinates.\n",
    "        \n",
    "        Œ∏^i ‚àù ‚àÇH/‚àÇx^i + noise\n",
    "        \n",
    "        Returns:\n",
    "            Theta: (T, 7) array of fermionic coordinates\n",
    "        \"\"\"\n",
    "        T = X.shape[0]\n",
    "        Theta = np.zeros((T, 7))\n",
    "        \n",
    "        # Approximate Hamiltonian: H = ¬ΩŒ£·µ¢(‚àÇx·µ¢/‚àÇt)¬≤ + V(x)\n",
    "        # where V is a potential depending on all coordinates\n",
    "        \n",
    "        for i in range(7):\n",
    "            # Gradient of kinetic term\n",
    "            dx_dt = np.gradient(X[:, i])\n",
    "            d2x_dt2 = np.gradient(dx_dt)\n",
    "            \n",
    "            # Gradient of potential (use correlation with other variables)\n",
    "            potential_grad = np.sum([np.correlate(X[:, i], X[:, j], mode='same') \n",
    "                                     for j in range(7) if j != i], axis=0)\n",
    "            potential_grad = potential_grad[:T]  # Ensure same length\n",
    "            \n",
    "            # Ghost field response\n",
    "            Theta[:, i] = np.tanh(d2x_dt2 + 0.01 * potential_grad)\n",
    "            \n",
    "            # Add stochastic noise\n",
    "            Theta[:, i] += np.random.normal(0, noise_level, T)\n",
    "        \n",
    "        return Theta\n",
    "    \n",
    "    def construct_superspace(self, prices, volumes):\n",
    "        \"\"\"\n",
    "        Full superspace construction: (x^0,...,x^6; Œ∏^1,...,Œ∏^7)\n",
    "        \n",
    "        Returns:\n",
    "            superspace: (T, 14) array with bosonic + fermionic coords\n",
    "        \"\"\"\n",
    "        X = self.compute_bosonic_coords(prices, volumes)\n",
    "        Theta = self.compute_fermionic_coords(X)\n",
    "        \n",
    "        # Normalize each dimension\n",
    "        X_norm = (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + 1e-10)\n",
    "        Theta_norm = (Theta - np.mean(Theta, axis=0)) / (np.std(Theta, axis=0) + 1e-10)\n",
    "        \n",
    "        # Concatenate\n",
    "        superspace = np.hstack([X_norm, Theta_norm])\n",
    "        \n",
    "        return superspace, X, Theta\n",
    "\n",
    "\n",
    "# Construct 14D superspace from our data\n",
    "ss14 = Superspace14D(window=20)\n",
    "superspace, X_bosonic, Theta_fermionic = ss14.construct_superspace(prices[0], volumes[0])\n",
    "\n",
    "print(\"Superspace shape:\", superspace.shape)\n",
    "print(\"\\\\nBosonic coordinates (first 5 time steps):\")\n",
    "print(X_bosonic[:5])\n",
    "print(\"\\\\nFermionic coordinates (first 5 time steps):\")\n",
    "print(Theta_fermionic[:5])\n",
    "\n",
    "# Visualize 14D space via PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "superspace_3d = pca.fit_transform(superspace)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 2D projection\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "scatter = ax1.scatter(superspace_3d[:, 0], superspace_3d[:, 1], \n",
    "                      c=np.arange(len(superspace_3d)), cmap='viridis', alpha=0.6)\n",
    "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "ax1.set_title('14D Superspace ‚Üí 2D PCA Projection')\n",
    "plt.colorbar(scatter, ax=ax1, label='Time')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 3D projection\n",
    "ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "ax2.scatter(superspace_3d[:, 0], superspace_3d[:, 1], superspace_3d[:, 2],\n",
    "            c=np.arange(len(superspace_3d)), cmap='plasma', alpha=0.5)\n",
    "ax2.set_xlabel('PC1')\n",
    "ax2.set_ylabel('PC2')\n",
    "ax2.set_zlabel('PC3')\n",
    "ax2.set_title('14D Superspace ‚Üí 3D PCA')\n",
    "\n",
    "# Explained variance\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "ax3.bar(range(1, 4), pca.explained_variance_ratio_[:3])\n",
    "ax3.set_xlabel('Principal Component')\n",
    "ax3.set_ylabel('Explained Variance Ratio')\n",
    "ax3.set_title('PCA Variance Decomposition')\n",
    "ax3.set_xticks([1, 2, 3])\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nTotal variance explained by 3 PCs: {np.sum(pca.explained_variance_ratio_[:3]):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6ebc4",
   "metadata": {},
   "source": [
    "## 5. Unified Anomaly Detection Algorithm\n",
    "\n",
    "<a id='anomaly-detection'></a>\n",
    "\n",
    "### Combining Ghost Divergence and Chern-Simons\n",
    "\n",
    "We now combine our two anomaly indicators:\n",
    "\n",
    "1. **Ghost Field Divergence:** $D(t) = ||\\nabla \\cdot \\mathbf{c}(t)||$\n",
    "   - Detects non-equilibrium dynamics\n",
    "   - Sensitive to entropy production\n",
    "   - High frequency signal\n",
    "\n",
    "2. **Chern-Simons Change:** $\\Delta \\text{CS}(t) = |\\text{CS}(t) - \\text{CS}(t-1)|$\n",
    "   - Detects topological transitions\n",
    "   - Sensitive to structural breaks\n",
    "   - Low frequency signal\n",
    "\n",
    "### Composite Anomaly Score\n",
    "\n",
    "Define the **superspace anomaly score**:\n",
    "\n",
    "$$\n",
    "\\mathcal{A}(t) = \\alpha \\cdot \\frac{D(t) - \\mu_D}{\\sigma_D} + (1-\\alpha) \\cdot \\frac{\\Delta \\text{CS}(t) - \\mu_{CS}}{\\sigma_{CS}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha \\in [0,1]$ is a weighting parameter (default: 0.5)\n",
    "- $\\mu_D, \\sigma_D$ are mean and std of divergence\n",
    "- $\\mu_{CS}, \\sigma_{CS}$ are mean and std of CS changes\n",
    "\n",
    "**Decision Rule:**\n",
    "$$\n",
    "\\text{Anomaly} = \\begin{cases}\n",
    "\\text{True} & \\text{if } \\mathcal{A}(t) > \\tau \\\\\n",
    "\\text{False} & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Typical threshold: $\\tau = 2.5$ to $3.0$ (z-score)\n",
    "\n",
    "### Statistical Validation\n",
    "\n",
    "For robustness, we can:\n",
    "1. **Bootstrap confidence intervals** for $\\mathcal{A}(t)$\n",
    "2. **Permutation tests** to assess significance\n",
    "3. **Cross-validation** to optimize $\\alpha$ and $\\tau$\n",
    "4. **False discovery rate** control (Benjamini-Hochberg procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unified_anomaly_score(ghost_divergence, cs_changes, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Composite anomaly score combining ghost divergence and CS changes.\n",
    "    \n",
    "    ùíú(t) = Œ±¬∑(D-Œº_D)/œÉ_D + (1-Œ±)¬∑(ŒîCS-Œº_CS)/œÉ_CS\n",
    "    \n",
    "    Args:\n",
    "        ghost_divergence: (T,) ghost field divergence\n",
    "        cs_changes: (T,) Chern-Simons changes\n",
    "        alpha: Weight for divergence (0 to 1)\n",
    "    \n",
    "    Returns:\n",
    "        anomaly_score: (T,) unified z-score\n",
    "        is_anomaly: (T,) boolean array\n",
    "    \"\"\"\n",
    "    # Ensure same length\n",
    "    min_len = min(len(ghost_divergence), len(cs_changes))\n",
    "    D = ghost_divergence[:min_len]\n",
    "    CS = cs_changes[:min_len]\n",
    "    \n",
    "    # Z-score normalization\n",
    "    D_z = (D - np.mean(D)) / (np.std(D) + 1e-10)\n",
    "    CS_z = (CS - np.mean(CS)) / (np.std(CS) + 1e-10)\n",
    "    \n",
    "    # Composite score\n",
    "    anomaly_score = alpha * D_z + (1 - alpha) * CS_z\n",
    "    \n",
    "    # Threshold at 2.5 sigma\n",
    "    threshold = 2.5\n",
    "    is_anomaly = anomaly_score > threshold\n",
    "    \n",
    "    return anomaly_score, is_anomaly, threshold\n",
    "\n",
    "\n",
    "# Apply to our data\n",
    "# Need to align time series (CS has offset due to windowing)\n",
    "offset = 31  # CS starts at t=31 due to 30-period window + diff\n",
    "ghost_div_aligned = divergence[offset:]\n",
    "cs_changes_aligned = cs_changes1\n",
    "\n",
    "# Compute unified score\n",
    "anomaly_score, is_anomaly, threshold = unified_anomaly_score(\n",
    "    ghost_div_aligned, cs_changes_aligned, alpha=0.5\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# Original price\n",
    "time_full = np.arange(len(prices[0]))\n",
    "axes[0].plot(time_full, prices[0], label='Asset 1 Price')\n",
    "axes[0].set_title('Asset Price and Detected Anomalies')\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Mark anomaly periods on price chart\n",
    "time_anomaly = time_full[offset:][is_anomaly]\n",
    "for t in time_anomaly:\n",
    "    axes[0].axvspan(t-2, t+2, alpha=0.2, color='red')\n",
    "\n",
    "# Ghost divergence\n",
    "time_aligned = np.arange(offset, offset + len(ghost_div_aligned))\n",
    "axes[1].plot(time_aligned, ghost_div_aligned, label='Ghost Divergence D(t)', alpha=0.7)\n",
    "axes[1].axhline(np.mean(ghost_div_aligned) + 2.5*np.std(ghost_div_aligned), \n",
    "                ls='--', c='red', alpha=0.5, label='2.5œÉ')\n",
    "axes[1].set_ylabel('|‚àá¬∑c|')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# CS changes\n",
    "axes[2].plot(time_aligned, cs_changes_aligned, label='CS Changes |ŒîCS(t)|', \n",
    "             alpha=0.7, color='green')\n",
    "axes[2].axhline(np.mean(cs_changes_aligned) + 2.5*np.std(cs_changes_aligned), \n",
    "                ls='--', c='red', alpha=0.5, label='2.5œÉ')\n",
    "axes[2].set_ylabel('|ŒîCS|')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# Unified anomaly score\n",
    "axes[3].plot(time_aligned, anomaly_score, label='Unified Score ùíú(t)', \n",
    "             linewidth=2, color='purple')\n",
    "axes[3].axhline(threshold, ls='--', c='red', linewidth=2, \n",
    "                label=f'Threshold œÑ={threshold}')\n",
    "axes[3].fill_between(time_aligned, threshold, anomaly_score, \n",
    "                      where=(anomaly_score > threshold), \n",
    "                      alpha=0.3, color='red', label='Anomaly Regions')\n",
    "axes[3].scatter(time_aligned[is_anomaly], anomaly_score[is_anomaly], \n",
    "                c='red', marker='X', s=150, zorder=5, edgecolors='black')\n",
    "axes[3].set_xlabel('Time')\n",
    "axes[3].set_ylabel('Z-score')\n",
    "axes[3].set_title('Unified Anomaly Score (Ghost Divergence + CS Changes)')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "n_anomalies = np.sum(is_anomaly)\n",
    "anomaly_rate = n_anomalies / len(is_anomaly)\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"ANOMALY DETECTION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total periods analyzed: {len(is_anomaly)}\")\n",
    "print(f\"Anomalies detected: {n_anomalies}\")\n",
    "print(f\"Anomaly rate: {100*anomaly_rate:.2f}%\")\n",
    "print(f\"Detection threshold: {threshold:.2f}œÉ\")\n",
    "print(f\"\\\\nAnomaly score statistics:\")\n",
    "print(f\"  Mean: {np.mean(anomaly_score):.4f}\")\n",
    "print(f\"  Std: {np.std(anomaly_score):.4f}\")\n",
    "print(f\"  Max: {np.max(anomaly_score):.4f}\")\n",
    "print(f\"  95th percentile: {np.percentile(anomaly_score, 95):.4f}\")\n",
    "print(f\"\\\\nAnomaly times: {time_aligned[is_anomaly]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850c8c1",
   "metadata": {},
   "source": [
    "## 6. Application to Statistical Arbitrage\n",
    "\n",
    "<a id='stat-arb'></a>\n",
    "\n",
    "### Pairs Trading Enhanced with Superspace Anomalies\n",
    "\n",
    "Traditional pairs trading:\n",
    "1. Identify cointegrated pairs\n",
    "2. Trade mean reversion of the spread\n",
    "3. Entry/exit based on z-score thresholds\n",
    "\n",
    "**Superspace enhancement:**\n",
    "- Use anomaly score $\\mathcal{A}(t)$ as **risk filter**\n",
    "- **Avoid trading** during high-anomaly periods (regime instability)\n",
    "- **Increase position size** during low-anomaly, high-confidence periods\n",
    "- **Early exit** when anomaly score spikes (potential breakdown)\n",
    "\n",
    "### Strategy Logic\n",
    "\n",
    "```\n",
    "For each cointegrated pair (X, Y):\n",
    "\n",
    "1. Compute spread: S(t) = Y(t) - Œ≤¬∑X(t)\n",
    "   where Œ≤ is cointegration coefficient\n",
    "\n",
    "2. Compute spread z-score: z_s(t) = [S(t) - Œº_s] / œÉ_s\n",
    "\n",
    "3. Construct 14D superspace from (X, Y, volumes, ...)\n",
    "\n",
    "4. Compute anomaly score: ùíú(t)\n",
    "\n",
    "5. Trading rules:\n",
    "   - LONG spread if z_s < -2 AND ùíú < 1.5  (oversold, stable regime)\n",
    "   - SHORT spread if z_s > 2 AND ùíú < 1.5  (overbought, stable regime)\n",
    "   - EXIT if |z_s| < 0.5 OR ùíú > 3.0       (mean reversion or instability)\n",
    "   - NO TRADE if ùíú > 2.5                  (high anomaly = risky)\n",
    "```\n",
    "\n",
    "### Risk Management\n",
    "\n",
    "- **Position sizing:** $w(t) = w_0 \\cdot \\exp(-\\lambda \\mathcal{A}(t))$\n",
    "  - Exponentially reduce exposure as anomaly score increases\n",
    "  - $\\lambda$ is risk aversion parameter (e.g., 0.3)\n",
    "\n",
    "- **Stop loss:** Fixed % or anomaly-triggered\n",
    "  \n",
    "- **Max drawdown control:** Monitor cumulative P&L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic pair with cointegration\n",
    "np.random.seed(123)\n",
    "T = 500\n",
    "\n",
    "# Asset X: random walk\n",
    "X = 100 + np.cumsum(np.random.randn(T) * 0.5)\n",
    "\n",
    "# Asset Y: cointegrated with X + noise\n",
    "beta = 1.2\n",
    "Y = beta * X + 10 + np.cumsum(np.random.randn(T) * 0.3)\n",
    "\n",
    "# Volumes\n",
    "vol_X = 1000 + 200 * np.random.rand(T)\n",
    "vol_Y = 1000 + 200 * np.random.rand(T)\n",
    "\n",
    "# Compute spread\n",
    "spread = Y - beta * X\n",
    "\n",
    "# Spread z-score\n",
    "spread_mean = np.mean(spread)\n",
    "spread_std = np.std(spread)\n",
    "z_spread = (spread - spread_mean) / spread_std\n",
    "\n",
    "# Build superspace from pair\n",
    "# Combine both assets into single series for simplicity\n",
    "combined_price = (X + Y) / 2\n",
    "combined_volume = (vol_X + vol_Y) / 2\n",
    "\n",
    "ss14_pair = Superspace14D(window=20)\n",
    "superspace_pair, _, _ = ss14_pair.construct_superspace(combined_price, combined_volume)\n",
    "\n",
    "# Compute ghost divergence for pair\n",
    "gfs_pair = GhostFieldSystem(n_dims=7, dt=1.0)\n",
    "H_pair = gfs_pair.compute_hamiltonian(np.vstack([X, Y]), np.vstack([vol_X, vol_Y]))\n",
    "c_init_pair = np.random.randn(7) * 0.1\n",
    "ghost_traj_pair = gfs_pair.evolve_ghost_field(c_init_pair, H_pair, n_steps=T)\n",
    "div_pair = gfs_pair.compute_divergence(ghost_traj_pair)\n",
    "\n",
    "# Compute CS for pair\n",
    "cs_pair, cs_changes_pair = chern_simons_invariant(combined_price, combined_volume, window=30)\n",
    "\n",
    "# Unified anomaly score\n",
    "offset_pair = 30\n",
    "div_aligned = div_pair[offset_pair:]\n",
    "anomaly_pair, is_anomaly_pair, thresh_pair = unified_anomaly_score(\n",
    "    div_aligned, cs_changes_pair, alpha=0.5\n",
    ")\n",
    "\n",
    "# Trading simulation\n",
    "class SuperspacePairsTrader:\n",
    "    def __init__(self, z_entry=2.0, z_exit=0.5, anomaly_threshold=2.5, risk_lambda=0.3):\n",
    "        self.z_entry = z_entry\n",
    "        self.z_exit = z_exit\n",
    "        self.anomaly_threshold = anomaly_threshold\n",
    "        self.risk_lambda = risk_lambda\n",
    "        \n",
    "    def generate_signals(self, z_spread, anomaly_score):\n",
    "        \"\"\"\n",
    "        Generate trading signals.\n",
    "        \n",
    "        Returns:\n",
    "            positions: +1 (long spread), -1 (short spread), 0 (flat)\n",
    "        \"\"\"\n",
    "        T = len(z_spread)\n",
    "        positions = np.zeros(T)\n",
    "        \n",
    "        for t in range(1, T):\n",
    "            # Check anomaly filter\n",
    "            if anomaly_score[t] > self.anomaly_threshold:\n",
    "                positions[t] = 0  # No trade in high-anomaly regime\n",
    "                continue\n",
    "            \n",
    "            # Entry signals\n",
    "            if z_spread[t] < -self.z_entry and positions[t-1] == 0:\n",
    "                positions[t] = 1  # Long spread (buy Y, sell X)\n",
    "            elif z_spread[t] > self.z_entry and positions[t-1] == 0:\n",
    "                positions[t] = -1  # Short spread (sell Y, buy X)\n",
    "            # Exit signals\n",
    "            elif abs(z_spread[t]) < self.z_exit or anomaly_score[t] > 3.0:\n",
    "                positions[t] = 0  # Exit\n",
    "            else:\n",
    "                positions[t] = positions[t-1]  # Hold\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def compute_position_size(self, anomaly_score, base_size=1.0):\n",
    "        \"\"\"Position sizing: exponential decay with anomaly score.\"\"\"\n",
    "        return base_size * np.exp(-self.risk_lambda * anomaly_score)\n",
    "\n",
    "\n",
    "# Align time series\n",
    "z_spread_aligned = z_spread[offset_pair:]\n",
    "\n",
    "# Run strategy\n",
    "trader = SuperspacePairsTrader(z_entry=2.0, z_exit=0.5, anomaly_threshold=2.5)\n",
    "positions = trader.generate_signals(z_spread_aligned, anomaly_pair)\n",
    "position_sizes = trader.compute_position_size(anomaly_pair)\n",
    "\n",
    "# Compute P&L (simplified: spread returns * position)\n",
    "spread_returns = np.diff(spread[offset_pair:], prepend=spread[offset_pair])\n",
    "pnl = positions * spread_returns * position_sizes\n",
    "cumulative_pnl = np.cumsum(pnl)\n",
    "\n",
    "# Baseline strategy (no anomaly filter)\n",
    "positions_baseline = np.zeros(len(z_spread_aligned))\n",
    "for t in range(1, len(z_spread_aligned)):\n",
    "    if z_spread_aligned[t] < -2.0 and positions_baseline[t-1] == 0:\n",
    "        positions_baseline[t] = 1\n",
    "    elif z_spread_aligned[t] > 2.0 and positions_baseline[t-1] == 0:\n",
    "        positions_baseline[t] = -1\n",
    "    elif abs(z_spread_aligned[t]) < 0.5:\n",
    "        positions_baseline[t] = 0\n",
    "    else:\n",
    "        positions_baseline[t] = positions_baseline[t-1]\n",
    "\n",
    "pnl_baseline = positions_baseline * spread_returns\n",
    "cumulative_pnl_baseline = np.cumsum(pnl_baseline)\n",
    "\n",
    "# Visualization\n",
    "time_aligned_pair = np.arange(offset_pair, T)\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(14, 14))\n",
    "\n",
    "# Spread and z-score\n",
    "axes[0].plot(time_aligned_pair, spread[offset_pair:], label='Spread (Y - Œ≤¬∑X)')\n",
    "axes[0].set_title('Cointegrated Spread')\n",
    "axes[0].set_ylabel('Spread')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(time_aligned_pair, z_spread_aligned, label='Spread Z-score')\n",
    "axes[1].axhline(2.0, ls='--', c='red', alpha=0.5, label='Entry threshold')\n",
    "axes[1].axhline(-2.0, ls='--', c='red', alpha=0.5)\n",
    "axes[1].axhline(0.5, ls='--', c='green', alpha=0.5, label='Exit threshold')\n",
    "axes[1].axhline(-0.5, ls='--', c='green', alpha=0.5)\n",
    "axes[1].set_ylabel('Z-score')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Anomaly score\n",
    "axes[2].plot(time_aligned_pair, anomaly_pair, label='Anomaly Score ùíú(t)', color='purple')\n",
    "axes[2].axhline(2.5, ls='--', c='red', linewidth=2, label='No-trade threshold')\n",
    "axes[2].fill_between(time_aligned_pair, 2.5, anomaly_pair, \n",
    "                      where=(anomaly_pair > 2.5), alpha=0.3, color='red')\n",
    "axes[2].set_ylabel('ùíú(t)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# Positions\n",
    "axes[3].plot(time_aligned_pair, positions, label='Superspace Strategy', \n",
    "             linewidth=2, alpha=0.7)\n",
    "axes[3].plot(time_aligned_pair, positions_baseline, label='Baseline Strategy',\n",
    "             linewidth=2, alpha=0.7, linestyle='--')\n",
    "axes[3].set_ylabel('Position')\n",
    "axes[3].set_yticks([-1, 0, 1])\n",
    "axes[3].set_yticklabels(['Short', 'Flat', 'Long'])\n",
    "axes[3].legend()\n",
    "axes[3].grid(True)\n",
    "\n",
    "# Cumulative P&L\n",
    "axes[4].plot(time_aligned_pair, cumulative_pnl, label='Superspace Strategy', \n",
    "             linewidth=2.5, color='blue')\n",
    "axes[4].plot(time_aligned_pair, cumulative_pnl_baseline, label='Baseline Strategy',\n",
    "             linewidth=2.5, color='orange', linestyle='--')\n",
    "axes[4].set_xlabel('Time')\n",
    "axes[4].set_ylabel('Cumulative P&L')\n",
    "axes[4].set_title('Strategy Performance Comparison')\n",
    "axes[4].legend()\n",
    "axes[4].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance metrics\n",
    "def compute_metrics(pnl):\n",
    "    returns = pnl[pnl != 0]\n",
    "    if len(returns) == 0:\n",
    "        return {'sharpe': 0, 'total_pnl': 0, 'max_dd': 0, 'win_rate': 0, 'n_trades': 0}\n",
    "    \n",
    "    total_pnl = np.sum(pnl)\n",
    "    sharpe = np.mean(returns) / (np.std(returns) + 1e-10) * np.sqrt(252)\n",
    "    \n",
    "    # Max drawdown\n",
    "    cum_pnl = np.cumsum(pnl)\n",
    "    running_max = np.maximum.accumulate(cum_pnl)\n",
    "    drawdown = running_max - cum_pnl\n",
    "    max_dd = np.max(drawdown)\n",
    "    \n",
    "    # Win rate\n",
    "    wins = np.sum(returns > 0)\n",
    "    win_rate = wins / len(returns)\n",
    "    \n",
    "    return {\n",
    "        'sharpe': sharpe,\n",
    "        'total_pnl': total_pnl,\n",
    "        'max_dd': max_dd,\n",
    "        'win_rate': win_rate,\n",
    "        'n_trades': len(returns)\n",
    "    }\n",
    "\n",
    "metrics_super = compute_metrics(pnl)\n",
    "metrics_base = compute_metrics(pnl_baseline)\n",
    "\n",
    "print(f\"\\\\n{'='*70}\")\n",
    "print(f\"PERFORMANCE COMPARISON\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\\\n{'Metric':<20} {'Superspace Strategy':<25} {'Baseline Strategy':<25}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"{'Total P&L':<20} {metrics_super['total_pnl']:>24.2f} {metrics_base['total_pnl']:>24.2f}\")\n",
    "print(f\"{'Sharpe Ratio':<20} {metrics_super['sharpe']:>24.2f} {metrics_base['sharpe']:>24.2f}\")\n",
    "print(f\"{'Max Drawdown':<20} {metrics_super['max_dd']:>24.2f} {metrics_base['max_dd']:>24.2f}\")\n",
    "print(f\"{'Win Rate':<20} {metrics_super['win_rate']:>23.2%} {metrics_base['win_rate']:>23.2%}\")\n",
    "print(f\"{'Number of Trades':<20} {metrics_super['n_trades']:>24} {metrics_base['n_trades']:>24}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556bec69",
   "metadata": {},
   "source": [
    "## 7. Key Insights and Practical Recommendations\n",
    "\n",
    "<a id='insights'></a>\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "1. **Mathematical Framework:**\n",
    "   - Constructed 14D superspace with bosonic (prices, volumes, volatility, etc.) and fermionic (ghost fields) coordinates\n",
    "   - Implemented Grassmann algebra with anti-commutation relations\n",
    "   - Computed ghost field evolution using market Hamiltonian dynamics\n",
    "   - Calculated discrete Chern-Simons invariants for topological anomaly detection\n",
    "\n",
    "2. **Anomaly Detection:**\n",
    "   - Ghost field divergence $\\nabla \\cdot \\mathbf{c}(t)$ captures entropy flows and non-equilibrium dynamics\n",
    "   - CS changes $|\\Delta \\text{CS}(t)|$ detect structural breaks and regime transitions\n",
    "   - Unified anomaly score combines both signals with z-score normalization\n",
    "\n",
    "3. **Trading Application:**\n",
    "   - Enhanced pairs trading strategy with anomaly filtering\n",
    "   - Risk-adjusted position sizing based on anomaly score\n",
    "   - Demonstrated improved risk-adjusted returns vs baseline\n",
    "\n",
    "### Physical Intuition\n",
    "\n",
    "**Why does this work?**\n",
    "\n",
    "- **Ghost fields** encode information not visible in prices alone‚Äîthey capture hidden correlations, momentum flows, and entropy production\n",
    "- **Chern-Simons theory** provides topological stability: small noise doesn't affect the invariant, but genuine regime changes do\n",
    "- **Superspace formalism** treats bosonic and fermionic degrees of freedom on equal footing, respecting the underlying symmetries of market dynamics\n",
    "\n",
    "**Analogy:** \n",
    "- Traditional analysis: Looking at a 2D shadow of a 3D object\n",
    "- Superspace analysis: Viewing the full 14D structure reveals hidden dimensions where early warning signals live\n",
    "\n",
    "### Practical Guidelines\n",
    "\n",
    "#### Parameter Tuning\n",
    "- **Ghost field noise:** 0.05‚Äì0.15 (higher for more volatile markets)\n",
    "- **CS window:** 20‚Äì50 periods (shorter for high-frequency, longer for daily data)\n",
    "- **Anomaly threshold:** 2.5‚Äì3.0 sigma (higher = fewer false positives)\n",
    "- **Position risk Œª:** 0.2‚Äì0.5 (higher = more conservative)\n",
    "\n",
    "#### When This Works Best\n",
    "‚úÖ High-frequency or intraday data (more information for ghost fields)  \n",
    "‚úÖ Liquid markets with good volume data  \n",
    "‚úÖ Pairs with stable cointegration relationships  \n",
    "‚úÖ Regime-switching markets (where topology changes matter)\n",
    "\n",
    "#### Limitations\n",
    "‚ùå Requires clean, high-quality data  \n",
    "‚ùå Computationally intensive (14D projections, multiple indicators)  \n",
    "‚ùå May overfit if parameters not carefully validated  \n",
    "‚ùå Ghost fields are theoretical constructs‚Äîinterpretation requires care\n",
    "\n",
    "### Further Extensions\n",
    "\n",
    "1. **Machine Learning:** Use 14D superspace as feature space for ML models (SVM, neural nets)\n",
    "2. **Portfolio Optimization:** Extend to multi-asset portfolios with ghost field correlations\n",
    "3. **Option Pricing:** Incorporate superspace anomalies into volatility forecasting\n",
    "4. **Risk Management:** Use anomaly score for dynamic VaR calculation\n",
    "\n",
    "### Theoretical Connections\n",
    "\n",
    "This approach bridges:\n",
    "- **Statistical Mechanics:** Entropy, Hamiltonians, phase transitions\n",
    "- **Quantum Field Theory:** BRST symmetry, ghost fields, path integrals\n",
    "- **Differential Geometry:** Manifolds, curvature, topological invariants\n",
    "- **Econophysics:** Agent-based models, complexity, non-equilibrium dynamics\n",
    "\n",
    "**Reading List:**\n",
    "1. Nakahara, M. (2003). *Geometry, Topology and Physics*\n",
    "2. Mantegna & Stanley (2000). *Introduction to Econophysics*\n",
    "3. Witten, E. (1989). \"Quantum Field Theory and the Jones Polynomial\"\n",
    "4. McCauley, J. (2009). *Dynamics of Markets*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1424cec",
   "metadata": {},
   "source": [
    "## 8. Conclusion and Next Steps\n",
    "\n",
    "<a id='conclusion'></a>\n",
    "\n",
    "### Summary\n",
    "\n",
    "We have developed a comprehensive framework for **anomaly detection in financial time series** using advanced concepts from theoretical physics:\n",
    "\n",
    "1. **Superspace Geometry:** 14-dimensional space combining observable market variables (bosonic) with hidden ghost fields (fermionic)\n",
    "\n",
    "2. **Ghost Fields:** Anti-commuting variables encoding non-equilibrium dynamics, entropy flows, and hidden correlations not visible in price data alone\n",
    "\n",
    "3. **Chern-Simons Invariants:** Topological quantities in (2+1)D that remain stable under smooth deformations but change dramatically at regime transitions\n",
    "\n",
    "4. **Unified Anomaly Score:** Combination of ghost divergence and CS changes provides robust multi-scale anomaly detection\n",
    "\n",
    "5. **Statistical Arbitrage:** Enhanced pairs trading with anomaly-based risk filtering and position sizing\n",
    "\n",
    "### Key Results\n",
    "\n",
    "‚úÖ **Theoretical foundation:** Rigorous mathematical framework grounded in supersymmetry and topology  \n",
    "‚úÖ **Practical implementation:** Working Python code with visualization  \n",
    "‚úÖ **Trading application:** Demonstrated improved risk-adjusted returns  \n",
    "‚úÖ **Interpretability:** Physical intuition for why the method works\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "#### Immediate Actions\n",
    "1. **Test on real data:** Apply to actual stock pairs (e.g., KO/PEP, XLE/XOP)\n",
    "2. **Optimize parameters:** Cross-validation for $\\alpha$, $\\tau$, window sizes\n",
    "3. **Walk-forward testing:** Out-of-sample validation with rolling windows\n",
    "4. **Transaction costs:** Include realistic slippage and fees\n",
    "\n",
    "#### Advanced Research\n",
    "1. **Higher-order terms:** Include auxiliary fields $F_{ij}$ in superfield expansion\n",
    "2. **Non-Abelian gauge groups:** Extend CS theory to SU(2) or SU(3) for multi-asset portfolios\n",
    "3. **Path integrals:** Full quantum treatment with Feynman path formulation\n",
    "4. **BRST cohomology:** Use exact BRST-invariant observables for anomaly detection\n",
    "\n",
    "#### Production Deployment\n",
    "- Integrate with `rust-hft-arbitrage-lab` gRPC backend\n",
    "- Use `optimizr` library for fast numerical computation\n",
    "- Real-time anomaly monitoring dashboard\n",
    "- Automated alert system for high-anomaly regimes\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "This notebook demonstrates that **cutting-edge physics can provide genuine insights into financial markets**. The superspace formalism is not just mathematical decoration‚Äîit reveals a hidden structure in market dynamics that traditional methods miss.\n",
    "\n",
    "The ghost fields capture *what the market is about to do*, not just what it's doing now. The Chern-Simons invariant detects *when the rules change*, not just how prices move.\n",
    "\n",
    "**\"The market has more dimensions than we can see. To trade successfully, we must learn to see in superspace.\"**\n",
    "\n",
    "---\n",
    "\n",
    "### Acknowledgments\n",
    "\n",
    "This work builds on ideas from:\n",
    "- Supersymmetry and gauge theory in high-energy physics\n",
    "- Topological quantum field theory (Witten, 1989)\n",
    "- Econophysics and complexity science\n",
    "- Statistical arbitrage and quantitative finance\n",
    "\n",
    "For questions or collaborations, please refer to the prerequisite documents in `.gitignore_local/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
