{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b91a1c",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae147ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import requests\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup path\n",
    "import sys\n",
    "sys.path.append('/Users/melvinalvarez/Documents/Workspace/rust-hft-arbitrage-lab')\n",
    "\n",
    "# Import project modules\n",
    "from python import meanrev\n",
    "from python.api_keys import get_finnhub_key\n",
    "from python.universes import get_universe, get_available_universes\n",
    "from python.regime_detector import RegimeDetector, AdaptiveStrategySelector, get_regime_metrics\n",
    "from python.signal_monitor import SignalMonitor\n",
    "\n",
    "# Try Rust analytics (high-performance)\n",
    "try:\n",
    "    import hft_py\n",
    "    RUST_ANALYTICS = True\n",
    "    print(\"‚úÖ Rust analytics available - using optimized implementations\")\n",
    "except ImportError:\n",
    "    RUST_ANALYTICS = False\n",
    "    print(\"‚ö†Ô∏è  Rust analytics not available - using Python fallbacks\")\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.width = 120\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a07b30",
   "metadata": {},
   "source": [
    "## Universe Selection\n",
    "\n",
    "Choose from multiple pre-configured universes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available universes\n",
    "print(\"üìä Available Universes:\\n\" + \"=\"*60)\n",
    "for name, info in get_available_universes().items():\n",
    "    print(f\"  {name:20} {info['size']:3} symbols - {info['desc']}\")\n",
    "\n",
    "# SELECT YOUR UNIVERSE HERE:\n",
    "UNIVERSE = 'sp500_top100'  # Options: 'tech', 'finance', 'healthcare', 'energy', 'consumer', 'sp500_top100', 'crypto_major', 'etf_indices', etc.\n",
    "DAYS_BACK = 30\n",
    "RESOLUTION_MIN = 5\n",
    "\n",
    "print(f\"\\n‚úÖ Selected: {UNIVERSE} ({get_available_universes()[UNIVERSE]['size']} symbols)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d75a74",
   "metadata": {},
   "source": [
    "## Data Fetching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_finnhub_quote(symbol: str, api_key: str):\n",
    "    \"\"\"Fetch current quote from Finnhub.\"\"\"\n",
    "    url = \"https://finnhub.io/api/v1/quote\"\n",
    "    params = {\"symbol\": symbol, \"token\": api_key}\n",
    "    response = requests.get(url, params=params, timeout=10)\n",
    "    return response.json()\n",
    "\n",
    "def generate_historical_data(symbol: str, api_key: str, days_back: int, resolution_min: int):\n",
    "    \"\"\"Generate synthetic historical data anchored to current Finnhub price.\"\"\"\n",
    "    quote = fetch_finnhub_quote(symbol, api_key)\n",
    "    if 'c' not in quote or quote['c'] <= 0:\n",
    "        raise ValueError(f\"Could not fetch price for {symbol}\")\n",
    "    \n",
    "    current_price = quote['c']\n",
    "    is_crypto = ':' in symbol\n",
    "    candles_per_day = int((24 if is_crypto else 6.5) * 60 / resolution_min)\n",
    "    total_candles = days_back * candles_per_day\n",
    "    \n",
    "    timestamps = pd.date_range(end=datetime.now(), periods=total_candles, freq=f'{resolution_min}min')\n",
    "    np.random.seed(hash(symbol) % 2**32)\n",
    "    \n",
    "    # Generate with regime switches\n",
    "    daily_vol = 0.03 if is_crypto else 0.02\n",
    "    vol_per_step = daily_vol * np.sqrt(resolution_min / (24 * 60))\n",
    "    prices = np.zeros(total_candles)\n",
    "    prices[0] = current_price * 0.95\n",
    "    \n",
    "    regime_length = candles_per_day * 5\n",
    "    regimes = np.random.choice(['trend', 'mean_revert', 'high_vol'], \n",
    "                               size=total_candles // regime_length + 1, p=[0.3, 0.5, 0.2])\n",
    "    \n",
    "    for i in range(1, total_candles):\n",
    "        regime = regimes[i // regime_length]\n",
    "        shock = np.random.randn()\n",
    "        \n",
    "        if regime == 'trend':\n",
    "            drift, vol = 0.0003, vol_per_step * 0.8\n",
    "        elif regime == 'high_vol':\n",
    "            drift, vol = 0, vol_per_step * 1.5\n",
    "        else:\n",
    "            drift = -0.1 * (prices[i-1] - current_price) / current_price\n",
    "            vol = vol_per_step\n",
    "        \n",
    "        prices[i] = np.clip(prices[i-1] * (1 + drift + vol * shock), \n",
    "                           current_price * 0.7, current_price * 1.3)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Close': prices,\n",
    "        'Open': np.roll(prices, 1),\n",
    "        'High': prices * (1 + np.abs(np.random.randn(total_candles)) * 0.002),\n",
    "        'Low': prices * (1 - np.abs(np.random.randn(total_candles)) * 0.002),\n",
    "        'Volume': 1e6 * (1 + np.abs(np.diff(prices, prepend=prices[0])) / prices * 100)\n",
    "    }, index=timestamps)\n",
    "\n",
    "def fetch_universe_data(universe: str, api_key: str, days_back: int, resolution_min: int):\n",
    "    \"\"\"Fetch data for entire universe.\"\"\"\n",
    "    symbols = get_universe(universe)\n",
    "    data = {}\n",
    "    print(f\"üì° Fetching {len(symbols)} symbols...\")\n",
    "    \n",
    "    for i, symbol in enumerate(symbols, 1):\n",
    "        try:\n",
    "            print(f\"   [{i}/{len(symbols)}] {symbol}...\", end=\" \", flush=True)\n",
    "            df = generate_historical_data(symbol, api_key, days_back, resolution_min)\n",
    "            data[symbol] = df\n",
    "            print(f\"‚úì ({len(df)} candles)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Fetched {len(data)}/{len(symbols)} symbols\")\n",
    "    return data\n",
    "\n",
    "print(\"‚úÖ Data fetching functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54581609",
   "metadata": {},
   "source": [
    "## Fetch Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key\n",
    "api_key = get_finnhub_key()\n",
    "if not api_key:\n",
    "    raise ValueError(\"Finnhub API key not found\")\n",
    "\n",
    "# Fetch data\n",
    "print(f\"‚è≥ Fetching {UNIVERSE} data...\")\n",
    "data_dict = fetch_universe_data(UNIVERSE, api_key, DAYS_BACK, RESOLUTION_MIN)\n",
    "\n",
    "# Extract prices\n",
    "prices = pd.DataFrame({sym: df['Close'] for sym, df in data_dict.items()})\n",
    "prices = prices.fillna(method='ffill').fillna(method='bfill')  # Handle any missing data\n",
    "\n",
    "print(f\"\\n‚úÖ Data ready!\")\n",
    "print(f\"   Shape: {prices.shape[0]:,} timestamps √ó {prices.shape[1]} symbols\")\n",
    "print(f\"   Total data points: {prices.size:,}\")\n",
    "print(f\"   Date range: {prices.index[0]} to {prices.index[-1]}\")\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296d0a6",
   "metadata": {},
   "source": [
    "## Regime Detection\n",
    "\n",
    "Detect market regimes for each asset using Hurst exponent, autocorrelation, and trend analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize regime detector and monitoring\n",
    "regime_detector = RegimeDetector(lookback_window=100)\n",
    "monitor = SignalMonitor(alert_file='data/alerts.jsonl', verbose=True)\n",
    "\n",
    "# Compute returns\n",
    "returns = prices.pct_change().fillna(0)\n",
    "\n",
    "# Detect regimes for all assets\n",
    "print(\"üîç Detecting market regimes...\")\n",
    "regime_results = regime_detector.detect_multi_regime(returns)\n",
    "\n",
    "# Display regime summary\n",
    "regime_counts = regime_results['regime'].value_counts()\n",
    "print(f\"\\nüìä Regime Distribution:\")\n",
    "for regime, count in regime_counts.items():\n",
    "    pct = count / len(regime_results) * 100\n",
    "    print(f\"   {regime:20} {count:3} assets ({pct:.1f}%)\")\n",
    "\n",
    "# Show top mean-reverting assets\n",
    "mean_rev_assets = regime_results[regime_results['regime'] == 'mean_reverting'].sort_values('hurst')\n",
    "print(f\"\\nüéØ Top 10 Mean-Reverting Assets (by Hurst exponent):\")\n",
    "print(mean_rev_assets[['regime', 'hurst', 'autocorr', 'volatility']].head(10))\n",
    "\n",
    "regime_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e2c1e",
   "metadata": {},
   "source": [
    "## High-Performance Analytics with Rust\n",
    "\n",
    "Use Rust for computationally intensive operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUST_ANALYTICS:\n",
    "    print(\"‚ö° Using Rust analytics for high performance...\")\n",
    "    \n",
    "    # Convert to numpy for Rust\n",
    "    returns_np = returns.values\n",
    "    \n",
    "    # Compute correlation matrix (Rust)\n",
    "    import time\n",
    "    start = time.time()\n",
    "    corr_matrix = hft_py.analytics.compute_correlation_matrix(returns_np)\n",
    "    rust_time = time.time() - start\n",
    "    \n",
    "    # Compare with pandas\n",
    "    start = time.time()\n",
    "    corr_pandas = returns.corr().values\n",
    "    pandas_time = time.time() - start\n",
    "    \n",
    "    print(f\"   Rust time: {rust_time:.3f}s\")\n",
    "    print(f\"   Pandas time: {pandas_time:.3f}s\")\n",
    "    print(f\"   Speedup: {pandas_time/rust_time:.1f}x faster\")\n",
    "    \n",
    "    # Compute PCA (Rust)\n",
    "    print(\"\\nüî¨ Computing PCA...\")\n",
    "    components, explained_var = hft_py.analytics.compute_pca(returns_np, n_components=10)\n",
    "    \n",
    "    explained_ratio = explained_var / explained_var.sum()\n",
    "    print(f\"   Top 10 components explain {explained_ratio.sum():.1%} of variance\")\n",
    "    print(f\"   PC1: {explained_ratio[0]:.1%}, PC2: {explained_ratio[1]:.1%}, PC3: {explained_ratio[2]:.1%}\")\n",
    "    \n",
    "    corr_df = pd.DataFrame(corr_matrix, index=prices.columns, columns=prices.columns)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Using Python analytics (slower for large datasets)\")\n",
    "    corr_df = returns.corr()\n",
    "\n",
    "print(\"\\n‚úÖ Analytics complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3042a5a0",
   "metadata": {},
   "source": [
    "## Mean Reversion Signals with Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80081d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute z-scores for mean reversion\n",
    "window = 50\n",
    "\n",
    "if RUST_ANALYTICS:\n",
    "    print(\"‚ö° Computing z-scores with Rust...\")\n",
    "    zscores_np = hft_py.analytics.compute_zscores(prices.values, window)\n",
    "    zscores = pd.DataFrame(zscores_np, index=prices.index, columns=prices.columns)\n",
    "else:\n",
    "    print(\"‚öôÔ∏è  Computing z-scores with Python...\")\n",
    "    zscores = (prices - prices.rolling(window).mean()) / prices.rolling(window).std()\n",
    "\n",
    "# Monitor signals\n",
    "latest_zscores = zscores.iloc[-1]\n",
    "print(f\"\\nüö® Checking for signal alerts (threshold: ¬±{monitor.thresholds['signal_strength']})...\")\n",
    "\n",
    "alerts = []\n",
    "for symbol in latest_zscores.index:\n",
    "    zscore = latest_zscores[symbol]\n",
    "    if not np.isnan(zscore):\n",
    "        alert = monitor.check_signal_threshold(symbol, zscore, \"z_score\")\n",
    "        if alert:\n",
    "            alerts.append(alert)\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {len(alerts)} alerts\")\n",
    "\n",
    "# Display strongest signals\n",
    "strong_signals = latest_zscores[abs(latest_zscores) > 2.0].sort_values(key=abs, ascending=False)\n",
    "print(f\"\\nüìä Strongest Signals (|z| > 2.0): {len(strong_signals)}\")\n",
    "if len(strong_signals) > 0:\n",
    "    print(strong_signals.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c9202",
   "metadata": {},
   "source": [
    "## Visualization: Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show correlation heatmap for subset\n",
    "n_show = min(30, len(corr_df))\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=corr_df.iloc[:n_show, :n_show].values,\n",
    "    x=corr_df.columns[:n_show],\n",
    "    y=corr_df.index[:n_show],\n",
    "    colorscale='RdBu',\n",
    "    zmid=0,\n",
    "    text=corr_df.iloc[:n_show, :n_show].values,\n",
    "    texttemplate='%{text:.2f}',\n",
    "    textfont={\"size\": 8}\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Correlation Matrix ({UNIVERSE}, first {n_show} assets)\",\n",
    "    width=900,\n",
    "    height=800\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "avg_corr = corr_df.values[np.triu_indices_from(corr_df.values, k=1)].mean()\n",
    "print(f\"Average correlation: {avg_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98ed2d",
   "metadata": {},
   "source": [
    "## Alert Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get alert summary\n",
    "alert_summary = monitor.get_alert_summary()\n",
    "\n",
    "if len(alert_summary) > 0:\n",
    "    print(f\"üìã Alert Summary: {len(alert_summary)} total alerts\\n\")\n",
    "    \n",
    "    # Count by severity\n",
    "    severity_counts = alert_summary['severity'].value_counts()\n",
    "    print(\"By Severity:\")\n",
    "    for severity, count in severity_counts.items():\n",
    "        print(f\"   {severity:10} {count:3} alerts\")\n",
    "    \n",
    "    # Count by type\n",
    "    type_counts = alert_summary['type'].value_counts()\n",
    "    print(\"\\nBy Type:\")\n",
    "    for alert_type, count in type_counts.items():\n",
    "        print(f\"   {alert_type:15} {count:3} alerts\")\n",
    "    \n",
    "    print(\"\\nRecent Alerts:\")\n",
    "    display(alert_summary[['symbol', 'type', 'severity', 'message', 'value']].tail(10))\n",
    "else:\n",
    "    print(\"No alerts generated (all signals below threshold)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88bbea",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "### Key Metrics:\n",
    "- **Universe Size**: Large-scale analysis capability\n",
    "- **Rust Performance**: Significant speedup for computations\n",
    "- **Regime Detection**: Automated market state identification\n",
    "- **Signal Monitoring**: Real-time alert system\n",
    "\n",
    "### Next Steps:\n",
    "1. Implement adaptive position sizing based on regime\n",
    "2. Add portfolio optimization with risk constraints\n",
    "3. Backtest strategies with transaction costs\n",
    "4. Set up live monitoring with webhooks/email alerts"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
