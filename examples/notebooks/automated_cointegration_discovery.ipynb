{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from scipy.stats import norm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56da2e4",
   "metadata": {},
   "source": [
    "## üìä Data Collection: Real-World Stocks & ETFs\n",
    "\n",
    "We'll analyze:\n",
    "- **Tech Sector**: AAPL, MSFT, GOOGL, AMZN, META, NVDA\n",
    "- **Financial Sector**: JPM, BAC, WFC, GS, MS, C\n",
    "- **Energy Sector**: XOM, CVX, COP, SLB, EOG\n",
    "- **ETFs**: SPY, QQQ, IWM, DIA, XLF, XLE, XLK\n",
    "- **Precious Metals**: GLD, SLV, GDX, GDXJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define universe of assets\n",
    "assets = {\n",
    "    'Tech': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'NFLX'],\n",
    "    'Finance': ['JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'BLK', 'SCHW'],\n",
    "    'Energy': ['XOM', 'CVX', 'COP', 'SLB', 'EOG', 'PSX', 'MPC', 'VLO'],\n",
    "    'Healthcare': ['JNJ', 'UNH', 'PFE', 'ABBV', 'TMO', 'MRK', 'ABT', 'LLY'],\n",
    "    'ETFs': ['SPY', 'QQQ', 'IWM', 'DIA', 'XLF', 'XLE', 'XLK', 'XLV', 'XLI'],\n",
    "    'Metals': ['GLD', 'SLV', 'GDX', 'GDXJ', 'PPLT', 'PALL']\n",
    "}\n",
    "\n",
    "# Flatten to single list\n",
    "all_symbols = [s for sector in assets.values() for s in sector]\n",
    "\n",
    "print(f\"üìà Total assets: {len(all_symbols)}\")\n",
    "for sector, symbols in assets.items():\n",
    "    print(f\"  {sector}: {len(symbols)} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63cb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download historical data (2 years)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=730)\n",
    "\n",
    "print(f\"üì• Downloading data from {start_date.date()} to {end_date.date()}...\")\n",
    "\n",
    "data = yf.download(\n",
    "    all_symbols,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    progress=True\n",
    ")['Adj Close']\n",
    "\n",
    "# Remove symbols with insufficient data\n",
    "min_data_points = 400\n",
    "data = data.dropna(axis=1, thresh=min_data_points)\n",
    "\n",
    "print(f\"\\n‚úÖ Downloaded {len(data.columns)} symbols with {len(data)} data points\")\n",
    "print(f\"\\nData shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c196c14",
   "metadata": {},
   "source": [
    "## üî¨ Core Functions: Statistical Tests & OU Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cointegration(y, x, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Engle-Granger cointegration test.\n",
    "    \n",
    "    Returns:\n",
    "        dict: beta, adf_stat, p_value, cointegrated\n",
    "    \"\"\"\n",
    "    # Step 1: OLS regression\n",
    "    beta = np.polyfit(x, y, 1)[0]\n",
    "    residuals = y - beta * x\n",
    "    \n",
    "    # Step 2: ADF test on residuals\n",
    "    adf_result = adfuller(residuals, autolag='AIC')\n",
    "    adf_stat = adf_result[0]\n",
    "    p_value = adf_result[1]\n",
    "    \n",
    "    is_cointegrated = p_value < alpha\n",
    "    \n",
    "    return {\n",
    "        'beta': beta,\n",
    "        'adf_statistic': adf_stat,\n",
    "        'p_value': p_value,\n",
    "        'cointegrated': is_cointegrated,\n",
    "        'residuals': residuals\n",
    "    }\n",
    "\n",
    "def estimate_ou_params(spread, dt=1/252):\n",
    "    \"\"\"\n",
    "    Estimate Ornstein-Uhlenbeck parameters via discrete approximation.\n",
    "    \n",
    "    Model: X_t = mu + phi*X_{t-1} + epsilon\n",
    "    \n",
    "    Returns:\n",
    "        dict: kappa, theta, sigma, half_life\n",
    "    \"\"\"\n",
    "    X = spread[:-1]\n",
    "    Y = spread[1:]\n",
    "    \n",
    "    # OLS: Y = mu + phi*X + epsilon\n",
    "    mu, phi = np.polyfit(X, Y, 1)\n",
    "    residuals = Y - (mu + phi * X)\n",
    "    sigma_epsilon = np.std(residuals)\n",
    "    \n",
    "    # Convert to continuous-time parameters\n",
    "    kappa = -np.log(phi) / dt if phi > 0 and phi < 1 else np.nan\n",
    "    theta = mu / (1 - phi) if phi != 1 else np.nan\n",
    "    sigma = sigma_epsilon * np.sqrt(-2 * np.log(phi) / dt / (1 - phi**2)) if phi > 0 and phi < 1 else np.nan\n",
    "    half_life = np.log(2) / kappa if kappa > 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'kappa': kappa,\n",
    "        'theta': theta,\n",
    "        'sigma': sigma,\n",
    "        'half_life': half_life\n",
    "    }\n",
    "\n",
    "def hurst_exponent(series, max_lag=20):\n",
    "    \"\"\"\n",
    "    Calculate Hurst exponent via Rescaled Range (R/S) analysis.\n",
    "    \n",
    "    H < 0.5: mean-reverting\n",
    "    H = 0.5: random walk\n",
    "    H > 0.5: trending\n",
    "    \"\"\"\n",
    "    lags = range(2, max_lag)\n",
    "    tau = []\n",
    "    rs = []\n",
    "    \n",
    "    for lag in lags:\n",
    "        n_blocks = len(series) // lag\n",
    "        if n_blocks < 2:\n",
    "            continue\n",
    "            \n",
    "        rs_values = []\n",
    "        for i in range(n_blocks):\n",
    "            block = series[i*lag:(i+1)*lag]\n",
    "            \n",
    "            # Mean-adjusted cumulative sum\n",
    "            mean_adj = block - np.mean(block)\n",
    "            cum_sum = np.cumsum(mean_adj)\n",
    "            \n",
    "            # Range\n",
    "            R = np.max(cum_sum) - np.min(cum_sum)\n",
    "            \n",
    "            # Standard deviation\n",
    "            S = np.std(block)\n",
    "            \n",
    "            if S > 0 and R > 0:\n",
    "                rs_values.append(R / S)\n",
    "        \n",
    "        if rs_values:\n",
    "            tau.append(lag)\n",
    "            rs.append(np.mean(rs_values))\n",
    "    \n",
    "    if len(tau) < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    # Linear regression: log(R/S) ~ H * log(tau)\n",
    "    H = np.polyfit(np.log(tau), np.log(rs), 1)[0]\n",
    "    \n",
    "    return H\n",
    "\n",
    "print(\"‚úÖ Statistical functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d015dd8",
   "metadata": {},
   "source": [
    "## ‚ö° HJB PDE Solver for Optimal Boundaries\n",
    "\n",
    "### Numerical Solution via Finite Differences\n",
    "\n",
    "Discretize the HJB equation:\n",
    "\n",
    "$$\\rho V_i = \\kappa(\\theta - x_i)\\frac{V_{i+1} - V_{i-1}}{2\\Delta x} + \\frac{\\sigma^2}{2}\\frac{V_{i+1} - 2V_i + V_{i-1}}{(\\Delta x)^2}$$\n",
    "\n",
    "Iterate until convergence to find value function $V(x)$ and optimal boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_hjb_ou(kappa, theta, sigma, rho=0.04, transaction_cost=0.001, \n",
    "                 n_points=200, max_iter=2000, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Solve HJB equation for optimal switching boundaries.\n",
    "    \n",
    "    Args:\n",
    "        kappa: mean-reversion speed\n",
    "        theta: long-term mean\n",
    "        sigma: volatility\n",
    "        rho: discount rate\n",
    "        transaction_cost: cost per trade\n",
    "        n_points: grid points\n",
    "        max_iter: max iterations\n",
    "        tol: convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "        dict: x grid, value function V, lower/upper boundaries\n",
    "    \"\"\"\n",
    "    # State space: theta ¬± 4 standard deviations\n",
    "    sigma_inf = sigma / np.sqrt(2 * kappa)\n",
    "    x_min = theta - 4 * sigma_inf\n",
    "    x_max = theta + 4 * sigma_inf\n",
    "    x = np.linspace(x_min, x_max, n_points)\n",
    "    dx = x[1] - x[0]\n",
    "    \n",
    "    # Initialize value function\n",
    "    V = np.zeros(n_points)\n",
    "    \n",
    "    # Iterative solver\n",
    "    for iteration in range(max_iter):\n",
    "        V_old = V.copy()\n",
    "        \n",
    "        for i in range(1, n_points - 1):\n",
    "            # Drift term\n",
    "            drift = kappa * (theta - x[i]) * (V[i+1] - V[i-1]) / (2 * dx)\n",
    "            \n",
    "            # Diffusion term\n",
    "            diffusion = 0.5 * sigma**2 * (V[i+1] - 2*V[i] + V[i-1]) / dx**2\n",
    "            \n",
    "            # Update\n",
    "            V[i] = (drift + diffusion) / rho\n",
    "        \n",
    "        # Boundary conditions (Neumann)\n",
    "        V[0] = V[1]\n",
    "        V[-1] = V[-2]\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.max(np.abs(V - V_old)) < tol:\n",
    "            break\n",
    "    \n",
    "    # Find optimal boundaries (where V' = ¬±1)\n",
    "    V_prime = np.gradient(V, dx)\n",
    "    \n",
    "    # Lower boundary (buy signal): V' ‚âà 1\n",
    "    lower_half = n_points // 2\n",
    "    lower_idx = np.argmin(np.abs(V_prime[:lower_half] - 1))\n",
    "    lower_boundary = x[lower_idx]\n",
    "    \n",
    "    # Upper boundary (sell signal): V' ‚âà -1\n",
    "    upper_idx = lower_half + np.argmin(np.abs(V_prime[lower_half:] + 1))\n",
    "    upper_boundary = x[upper_idx]\n",
    "    \n",
    "    return {\n",
    "        'x': x,\n",
    "        'V': V,\n",
    "        'V_prime': V_prime,\n",
    "        'lower_boundary': lower_boundary,\n",
    "        'upper_boundary': upper_boundary,\n",
    "        'iterations': iteration + 1\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ HJB solver defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867eebe",
   "metadata": {},
   "source": [
    "## üéØ Backtest Engine with Optimal Switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_optimal_switching(spread, lower_bound, upper_bound, transaction_cost=0.001):\n",
    "    \"\"\"\n",
    "    Backtest optimal switching strategy.\n",
    "    \n",
    "    Rules:\n",
    "    - Buy when spread < lower_bound\n",
    "    - Sell when spread > upper_bound\n",
    "    - Exit when spread crosses theta (zero)\n",
    "    \"\"\"\n",
    "    position = 0  # -1 (short), 0 (flat), +1 (long)\n",
    "    cash = 0\n",
    "    trades = []\n",
    "    pnl = []\n",
    "    \n",
    "    for i, z in enumerate(spread):\n",
    "        current_pnl = cash + position * z\n",
    "        pnl.append(current_pnl)\n",
    "        \n",
    "        # Entry signals\n",
    "        if position == 0:\n",
    "            if z < lower_bound:\n",
    "                # Buy spread (expect mean-reversion up)\n",
    "                position = 1\n",
    "                cash -= z * (1 + transaction_cost)\n",
    "                trades.append({'date': i, 'action': 'BUY', 'price': z, 'position': position})\n",
    "            elif z > upper_bound:\n",
    "                # Short spread (expect mean-reversion down)\n",
    "                position = -1\n",
    "                cash += z * (1 - transaction_cost)\n",
    "                trades.append({'date': i, 'action': 'SELL', 'price': z, 'position': position})\n",
    "        \n",
    "        # Exit signals (cross mean)\n",
    "        elif position == 1 and z > 0:\n",
    "            # Close long\n",
    "            cash += z * (1 - transaction_cost)\n",
    "            position = 0\n",
    "            trades.append({'date': i, 'action': 'CLOSE_LONG', 'price': z, 'position': position})\n",
    "        \n",
    "        elif position == -1 and z < 0:\n",
    "            # Close short\n",
    "            cash -= z * (1 + transaction_cost)\n",
    "            position = 0\n",
    "            trades.append({'date': i, 'action': 'CLOSE_SHORT', 'price': z, 'position': position})\n",
    "    \n",
    "    # Close any open position at end\n",
    "    if position != 0:\n",
    "        cash += position * spread.iloc[-1] * (1 - transaction_cost * np.sign(position))\n",
    "        position = 0\n",
    "    \n",
    "    pnl = np.array(pnl)\n",
    "    returns = np.diff(pnl) / (np.abs(pnl[:-1]) + 1e-10)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_return = pnl[-1]\n",
    "    sharpe = np.mean(returns) / (np.std(returns) + 1e-10) * np.sqrt(252)\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cummax = np.maximum.accumulate(pnl)\n",
    "    drawdown = (pnl - cummax) / (cummax + 1e-10)\n",
    "    max_dd = np.min(drawdown)\n",
    "    \n",
    "    # Win rate\n",
    "    trade_pnl = [trades[i+1]['price'] - trades[i]['price'] \n",
    "                 for i in range(0, len(trades)-1, 2) if i+1 < len(trades)]\n",
    "    win_rate = np.sum(np.array(trade_pnl) > 0) / len(trade_pnl) if trade_pnl else 0\n",
    "    \n",
    "    return {\n",
    "        'total_return': total_return,\n",
    "        'sharpe': sharpe,\n",
    "        'max_dd': max_dd,\n",
    "        'num_trades': len(trades),\n",
    "        'win_rate': win_rate,\n",
    "        'pnl': pnl,\n",
    "        'trades': trades\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Backtest engine defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905aa057",
   "metadata": {},
   "source": [
    "## üîç Comprehensive Pair Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9906fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pair(symbol1, symbol2, data, significance=0.05, min_hurst=0.45):\n",
    "    \"\"\"\n",
    "    Comprehensive pair testing pipeline.\n",
    "    \n",
    "    Steps:\n",
    "    1. Test cointegration\n",
    "    2. Calculate spread\n",
    "    3. Validate mean-reversion (Hurst)\n",
    "    4. Estimate OU parameters\n",
    "    5. Solve HJB for optimal boundaries\n",
    "    6. Backtest with optimal switching\n",
    "    7. Calculate combined score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract price series\n",
    "        y = data[symbol1].dropna()\n",
    "        x = data[symbol2].dropna()\n",
    "        \n",
    "        # Align\n",
    "        common_idx = y.index.intersection(x.index)\n",
    "        if len(common_idx) < 100:\n",
    "            return None\n",
    "        \n",
    "        y = y.loc[common_idx].values\n",
    "        x = x.loc[common_idx].values\n",
    "        \n",
    "        # 1. Cointegration test\n",
    "        coint_result = test_cointegration(y, x, alpha=significance)\n",
    "        if not coint_result['cointegrated']:\n",
    "            return None\n",
    "        \n",
    "        # 2. Calculate spread\n",
    "        beta = coint_result['beta']\n",
    "        spread = pd.Series(y - beta * x)\n",
    "        \n",
    "        # 3. Hurst exponent\n",
    "        H = hurst_exponent(spread.values)\n",
    "        if np.isnan(H) or H > min_hurst:\n",
    "            return None\n",
    "        \n",
    "        # 4. OU parameters\n",
    "        ou_params = estimate_ou_params(spread)\n",
    "        if np.isnan(ou_params['kappa']) or ou_params['kappa'] <= 0:\n",
    "            return None\n",
    "        \n",
    "        # 5. HJB solver\n",
    "        hjb_result = solve_hjb_ou(\n",
    "            kappa=ou_params['kappa'],\n",
    "            theta=ou_params['theta'],\n",
    "            sigma=ou_params['sigma']\n",
    "        )\n",
    "        \n",
    "        # 6. Backtest\n",
    "        backtest_result = backtest_optimal_switching(\n",
    "            spread,\n",
    "            hjb_result['lower_boundary'],\n",
    "            hjb_result['upper_boundary']\n",
    "        )\n",
    "        \n",
    "        # 7. Combined score\n",
    "        coint_score = 1 - coint_result['p_value']\n",
    "        meanrev_score = (0.5 - H) / 0.2  # Higher for H < 0.5\n",
    "        profit_score = max(0, backtest_result['total_return'])\n",
    "        \n",
    "        combined_score = coint_score * meanrev_score * (1 + profit_score)\n",
    "        \n",
    "        return {\n",
    "            'pair': f\"{symbol1}-{symbol2}\",\n",
    "            'symbol1': symbol1,\n",
    "            'symbol2': symbol2,\n",
    "            'beta': beta,\n",
    "            'p_value': coint_result['p_value'],\n",
    "            'hurst': H,\n",
    "            'kappa': ou_params['kappa'],\n",
    "            'theta': ou_params['theta'],\n",
    "            'sigma': ou_params['sigma'],\n",
    "            'half_life': ou_params['half_life'],\n",
    "            'lower_boundary': hjb_result['lower_boundary'],\n",
    "            'upper_boundary': hjb_result['upper_boundary'],\n",
    "            'total_return': backtest_result['total_return'],\n",
    "            'sharpe': backtest_result['sharpe'],\n",
    "            'max_dd': backtest_result['max_dd'],\n",
    "            'num_trades': backtest_result['num_trades'],\n",
    "            'win_rate': backtest_result['win_rate'],\n",
    "            'coint_score': coint_score,\n",
    "            'meanrev_score': meanrev_score,\n",
    "            'profit_score': profit_score,\n",
    "            'combined_score': combined_score,\n",
    "            'spread': spread,\n",
    "            'pnl': backtest_result['pnl']\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Pair testing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f0430",
   "metadata": {},
   "source": [
    "## üöÄ Parallel Discovery Engine\n",
    "\n",
    "Test all pairs in parallel using ThreadPoolExecutor for maximum speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd8ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build list of pairs to test\n",
    "symbols = data.columns.tolist()\n",
    "n_symbols = len(symbols)\n",
    "\n",
    "# Generate all unique pairs\n",
    "pairs_to_test = []\n",
    "for i in range(n_symbols):\n",
    "    for j in range(i+1, n_symbols):\n",
    "        pairs_to_test.append((symbols[i], symbols[j]))\n",
    "\n",
    "print(f\"üîç Total pairs to test: {len(pairs_to_test)}\")\n",
    "print(f\"\\nExample pairs: {pairs_to_test[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bce216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_workers = 8  # Adjust based on your CPU\n",
    "max_pairs = 500  # Limit for notebook demo\n",
    "\n",
    "pairs_to_test_limited = pairs_to_test[:max_pairs]\n",
    "\n",
    "print(f\"üöÄ Testing {len(pairs_to_test_limited)} pairs with {n_workers} workers...\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = {\n",
    "        executor.submit(test_pair, sym1, sym2, data): (sym1, sym2)\n",
    "        for sym1, sym2 in pairs_to_test_limited\n",
    "    }\n",
    "    \n",
    "    # Process results with progress bar\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Testing pairs\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(results)} cointegrated & mean-reverting pairs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ad212",
   "metadata": {},
   "source": [
    "## üìä Results Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "if results:\n",
    "    results_df = pd.DataFrame([{\n",
    "        'pair': r['pair'],\n",
    "        'p_value': r['p_value'],\n",
    "        'hurst': r['hurst'],\n",
    "        'half_life': r['half_life'],\n",
    "        'kappa': r['kappa'],\n",
    "        'total_return': r['total_return'],\n",
    "        'sharpe': r['sharpe'],\n",
    "        'max_dd': r['max_dd'],\n",
    "        'num_trades': r['num_trades'],\n",
    "        'win_rate': r['win_rate'],\n",
    "        'combined_score': r['combined_score']\n",
    "    } for r in results])\n",
    "    \n",
    "    # Sort by combined score\n",
    "    results_df = results_df.sort_values('combined_score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nüìà Summary Statistics:\\n\")\n",
    "    print(f\"Total pairs tested: {len(pairs_to_test_limited)}\")\n",
    "    print(f\"Cointegrated pairs: {len(results)} ({len(results)/len(pairs_to_test_limited)*100:.1f}%)\")\n",
    "    print(f\"\\nAverage Return: {results_df['total_return'].mean():.2%}\")\n",
    "    print(f\"Average Sharpe: {results_df['sharpe'].mean():.2f}\")\n",
    "    print(f\"Average Win Rate: {results_df['win_rate'].mean():.2%}\")\n",
    "    print(f\"\\nBest Return: {results_df['total_return'].max():.2%}\")\n",
    "    print(f\"Best Sharpe: {results_df['sharpe'].max():.2f}\")\n",
    "    \n",
    "    print(\"\\n\\nüèÜ Top 20 Pairs by Combined Score:\\n\")\n",
    "    display(results_df.head(20))\n",
    "else:\n",
    "    print(\"‚ùå No cointegrated pairs found. Try different assets or longer history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Score Distribution\n",
    "if results:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Combined score distribution\n",
    "    axes[0, 0].hist(results_df['combined_score'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Combined Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Combined Scores')\n",
    "    axes[0, 0].axvline(results_df['combined_score'].median(), color='red', linestyle='--', label='Median')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Risk-Return scatter\n",
    "    scatter = axes[0, 1].scatter(\n",
    "        results_df['max_dd'],\n",
    "        results_df['total_return'],\n",
    "        s=results_df['num_trades'],\n",
    "        c=results_df['combined_score'],\n",
    "        cmap='viridis',\n",
    "        alpha=0.6,\n",
    "        edgecolors='black'\n",
    "    )\n",
    "    axes[0, 1].set_xlabel('Max Drawdown')\n",
    "    axes[0, 1].set_ylabel('Total Return')\n",
    "    axes[0, 1].set_title('Risk-Return Profile (size=trades, color=score)')\n",
    "    plt.colorbar(scatter, ax=axes[0, 1], label='Combined Score')\n",
    "    \n",
    "    # Hurst distribution\n",
    "    axes[1, 0].hist(results_df['hurst'], bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Hurst Exponent')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Distribution of Hurst Exponents')\n",
    "    axes[1, 0].axvline(0.5, color='red', linestyle='--', label='Random Walk (H=0.5)')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Half-life distribution\n",
    "    axes[1, 1].hist(results_df['half_life'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 1].set_xlabel('Half-Life (days)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Distribution of Mean-Reversion Half-Lives')\n",
    "    axes[1, 1].axvline(results_df['half_life'].median(), color='red', linestyle='--', label='Median')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b229697",
   "metadata": {},
   "source": [
    "## üéØ Deep Dive: Best Performing Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze best pair\n",
    "if results:\n",
    "    best_pair = results[0]\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Pair: {best_pair['pair']}\")\n",
    "    print(f\"\\nüìä Statistics:\")\n",
    "    print(f\"  Beta: {best_pair['beta']:.4f}\")\n",
    "    print(f\"  Cointegration p-value: {best_pair['p_value']:.4f}\")\n",
    "    print(f\"  Hurst Exponent: {best_pair['hurst']:.4f}\")\n",
    "    print(f\"\\nüåä OU Parameters:\")\n",
    "    print(f\"  Kappa (mean-reversion speed): {best_pair['kappa']:.4f}\")\n",
    "    print(f\"  Theta (long-term mean): {best_pair['theta']:.4f}\")\n",
    "    print(f\"  Sigma (volatility): {best_pair['sigma']:.4f}\")\n",
    "    print(f\"  Half-Life: {best_pair['half_life']:.2f} days\")\n",
    "    print(f\"\\n‚ö° Optimal Boundaries:\")\n",
    "    print(f\"  Lower (buy): {best_pair['lower_boundary']:.4f}\")\n",
    "    print(f\"  Upper (sell): {best_pair['upper_boundary']:.4f}\")\n",
    "    print(f\"\\nüí∞ Performance:\")\n",
    "    print(f\"  Total Return: {best_pair['total_return']:.2%}\")\n",
    "    print(f\"  Sharpe Ratio: {best_pair['sharpe']:.2f}\")\n",
    "    print(f\"  Max Drawdown: {best_pair['max_dd']:.2%}\")\n",
    "    print(f\"  Number of Trades: {best_pair['num_trades']}\")\n",
    "    print(f\"  Win Rate: {best_pair['win_rate']:.2%}\")\n",
    "    print(f\"\\nüéØ Combined Score: {best_pair['combined_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize best pair\n",
    "if results:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Spread with boundaries\n",
    "    spread = best_pair['spread']\n",
    "    axes[0].plot(spread.values, label='Spread', alpha=0.7)\n",
    "    axes[0].axhline(best_pair['theta'], color='black', linestyle='--', label='Mean (Œ∏)')\n",
    "    axes[0].axhline(best_pair['lower_boundary'], color='green', linestyle='--', label='Buy Signal')\n",
    "    axes[0].axhline(best_pair['upper_boundary'], color='red', linestyle='--', label='Sell Signal')\n",
    "    axes[0].fill_between(range(len(spread)), best_pair['lower_boundary'], \n",
    "                         best_pair['upper_boundary'], alpha=0.1, color='gray')\n",
    "    axes[0].set_ylabel('Spread')\n",
    "    axes[0].set_title(f'Spread Time Series: {best_pair[\"pair\"]}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # PnL curve\n",
    "    pnl = best_pair['pnl']\n",
    "    axes[1].plot(pnl, label='Cumulative PnL', color='blue', linewidth=2)\n",
    "    axes[1].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "    axes[1].fill_between(range(len(pnl)), 0, pnl, where=(pnl >= 0), \n",
    "                         color='green', alpha=0.3, label='Profit')\n",
    "    axes[1].fill_between(range(len(pnl)), 0, pnl, where=(pnl < 0), \n",
    "                         color='red', alpha=0.3, label='Loss')\n",
    "    axes[1].set_ylabel('PnL')\n",
    "    axes[1].set_title('Strategy Performance')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # Drawdown\n",
    "    cummax = np.maximum.accumulate(pnl)\n",
    "    drawdown = (pnl - cummax) / (cummax + 1e-10) * 100\n",
    "    axes[2].fill_between(range(len(drawdown)), 0, drawdown, color='red', alpha=0.5)\n",
    "    axes[2].set_ylabel('Drawdown (%)')\n",
    "    axes[2].set_xlabel('Time')\n",
    "    axes[2].set_title(f'Drawdown (Max: {best_pair[\"max_dd\"]:.2%})')\n",
    "    axes[2].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd9a2ce",
   "metadata": {},
   "source": [
    "## üìà Portfolio Construction: Top N Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e52697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build portfolio from top pairs\n",
    "if results:\n",
    "    top_n = 10\n",
    "    top_pairs = results[:top_n]\n",
    "    \n",
    "    print(f\"\\nüéØ Portfolio of Top {top_n} Pairs:\\n\")\n",
    "    \n",
    "    portfolio_metrics = {\n",
    "        'avg_return': np.mean([p['total_return'] for p in top_pairs]),\n",
    "        'avg_sharpe': np.mean([p['sharpe'] for p in top_pairs]),\n",
    "        'avg_max_dd': np.mean([p['max_dd'] for p in top_pairs]),\n",
    "        'avg_win_rate': np.mean([p['win_rate'] for p in top_pairs]),\n",
    "        'total_trades': sum([p['num_trades'] for p in top_pairs])\n",
    "    }\n",
    "    \n",
    "    print(f\"Average Return: {portfolio_metrics['avg_return']:.2%}\")\n",
    "    print(f\"Average Sharpe: {portfolio_metrics['avg_sharpe']:.2f}\")\n",
    "    print(f\"Average Max DD: {portfolio_metrics['avg_max_dd']:.2%}\")\n",
    "    print(f\"Average Win Rate: {portfolio_metrics['avg_win_rate']:.2%}\")\n",
    "    print(f\"Total Trades: {portfolio_metrics['total_trades']}\")\n",
    "    \n",
    "    # Display pairs\n",
    "    portfolio_df = pd.DataFrame([{\n",
    "        'Pair': p['pair'],\n",
    "        'Return': f\"{p['total_return']:.2%}\",\n",
    "        'Sharpe': f\"{p['sharpe']:.2f}\",\n",
    "        'Max DD': f\"{p['max_dd']:.2%}\",\n",
    "        'Win Rate': f\"{p['win_rate']:.2%}\",\n",
    "        'Trades': p['num_trades'],\n",
    "        'Score': f\"{p['combined_score']:.4f}\"\n",
    "    } for p in top_pairs])\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    display(portfolio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aade815",
   "metadata": {},
   "source": [
    "## üíæ Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "if results:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'cointegration_discovery_{timestamp}.csv'\n",
    "    \n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"\\n‚úÖ Results exported to: {filename}\")\n",
    "    print(f\"   {len(results_df)} pairs saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a4252",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### Statistical Validation\n",
    "1. **Cointegration** ensures long-term equilibrium relationship\n",
    "2. **Hurst < 0.5** confirms mean-reversion property\n",
    "3. **Half-life** indicates speed of reversion (optimal: 5-20 days)\n",
    "\n",
    "### Optimal Control\n",
    "1. **HJB equation** gives theoretically optimal boundaries\n",
    "2. **Viscosity solutions** handle non-smooth value functions\n",
    "3. **Transaction costs** significantly impact boundaries\n",
    "\n",
    "### Portfolio Construction\n",
    "1. **Diversify** across multiple pairs for risk reduction\n",
    "2. **Score ranking** balances statistical validity and profitability\n",
    "3. **Sector filtering** can improve economic interpretation\n",
    "\n",
    "### Risk Management\n",
    "1. Monitor **drawdowns** continuously\n",
    "2. Set **stop-losses** beyond optimal boundaries\n",
    "3. Adjust **position sizes** based on volatility\n",
    "4. **Walk-forward** testing for out-of-sample validation\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Real-time monitoring** with streaming data\n",
    "2. **Machine learning** for pair quality prediction\n",
    "3. **Multi-timeframe** analysis (daily, hourly, minute)\n",
    "4. **Options strategies** for leverage and hedging\n",
    "5. **Regime detection** to adapt to market conditions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
